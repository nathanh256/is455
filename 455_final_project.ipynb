{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "UekkzUwDavf2"
      },
      "outputs": [],
      "source": [
        "# ### Mount Drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "HfSN7hb4aphV"
      },
      "outputs": [],
      "source": [
        "### Imports\n",
        "\n",
        "import os, requests, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Constants\n",
        "\n",
        "WEIGHTS = {\"retweet\" : 3, \"like\" : 0.5 ,\"quote\" : 4 ,\"reply\" : 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "2k1VI619aNhd"
      },
      "outputs": [],
      "source": [
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAEqDUAEAAAAAPylQ7hO%2FoW9BuUjtiG608qAZJPg%3DKHFGBs8PtUg49u2TBLzina1UcfwkGtNuCJHlT55omuPiLUaIyi\"\n",
        "\n",
        "def response_health(r):\n",
        "  if r.status_code != 200:\n",
        "    raise Exception(\n",
        "    \"Request returned an error: {} {}\".format(\n",
        "      r.status_code, r.text\n",
        "    )\n",
        "  )\n",
        "    \n",
        "def bearer_oauth(r):\n",
        "  r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "  return r\n",
        "\n",
        "def send_request(url, params=None, print_status=False):\n",
        "  '''Send Request (url) with optional params. Returns json'''\n",
        "  # https://2.python-requests.org/en/master/api/#requests.request\n",
        "  if params == None:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
        "  else:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
        "  if print_status: print(\"Request response status: \", response.status_code)\n",
        "  response_health(response)\n",
        "  return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "VvapD2RKjCuA"
      },
      "outputs": [],
      "source": [
        "def get_user_data(name):\n",
        "  # data dictionary scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
        "\n",
        "  userFields = {\"user.fields\":\"created_at, description, entities, id, location, name, pinned_tweet_id, profile_image_url, protected, public_metrics, url, username, verified, withheld\".replace(\" \", \"\")}\n",
        "  user_json = send_request(f\"https://api.twitter.com/2/users/by/username/{name}\",params=userFields)\n",
        "  user_json = user_json[\"data\"]\n",
        "\n",
        "  outputDict = {}\n",
        "  outputDict['following_count'] = user_json['public_metrics']['following_count']\n",
        "  outputDict['tweet_count'] = user_json['public_metrics']['tweet_count']\n",
        "  outputDict['followers_count'] = user_json['public_metrics']['followers_count']\n",
        "  outputDict['listed_count'] = user_json['public_metrics']['listed_count']\n",
        "  outputDict['handle'] = user_json['username']\n",
        "  outputDict['name'] = user_json['name']\n",
        "  outputDict['id'] = user_json['id']\n",
        "  outputDict['verified'] = user_json['verified']\n",
        "  outputDict['protected'] = user_json['protected']\n",
        "  outputDict['created_at'] = user_json['created_at']\n",
        "  outputDict['description'] = user_json['description']\n",
        "\n",
        "  try:\n",
        "    test = user_json['pinned_tweet_id']\n",
        "    outputDict['hasPinnedTweet'] = True\n",
        "  except:\n",
        "    outputDict['hasPinnedTweet'] = False\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['urlsInDescription'] = len(user_json['entities']['description']['urls'])\n",
        "  except:\n",
        "    outputDict['urlsInDescription'] = 0\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['hashtagsInDescription'] = len(user_json['entities']['description']['hashtags'])\n",
        "  except:\n",
        "    outputDict['hashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['userWebsitesAdded'] = len(user_json['entities']['url']['urls'])\n",
        "  except:\n",
        "    outputDict['userWebsitesAdded'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['cashtagsInDescription'] = len(user_json['entities']['description']['cashtags'])\n",
        "  except:\n",
        "    outputDict['cashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['mentionsInDescription'] = len(user_json['entities']['description']['mentions'])\n",
        "  except:\n",
        "    outputDict['mentionsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  \n",
        "  return outputDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "cBRiEBATn6Kc"
      },
      "outputs": [],
      "source": [
        "def get_tweets_user(id, numTweets = 10, tweetsPerPage = 10, replies = False, weights=WEIGHTS, paginationToken = None):\n",
        "    import math\n",
        "    \n",
        "    # (there are 10 results returned per page by default)\n",
        "    if numTweets < tweetsPerPage:\n",
        "        print(\"numTweets must be greater than or equal to the number of tweets per page.\")\n",
        "        return\n",
        "\n",
        "    # to see data dictionary, click url and scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
        "    expansions = {\"expansions\":\"author_id, attachments.poll_ids, attachments.media_keys, entities.mentions.username, geo.place_id, in_reply_to_user_id, referenced_tweets.id,referenced_tweets.id.author_id\".replace(\" \", \"\")}\n",
        "    tweetFields = {\"tweet.fields\":\"attachments, author_id, context_annotations, conversation_id, created_at, entities, geo, id, in_reply_to_user_id, lang, public_metrics, possibly_sensitive, referenced_tweets, reply_settings, source, text, withheld\".replace(\" \", \"\")}\n",
        "    userFields = {\"user.fields\":\"public_metrics,username\"}\n",
        "    replyFields = {\"exclude\": \"replies\"}\n",
        "\n",
        "    outputDict = {'id':[],'handle':[],'followers':[], 'text':[], 'lang':[],'possibly_sensitive':[],'retweet_count':[],'reply_count':[],'like_count':[],'quote_count':[]\n",
        "        ,'reply_settings':[],'source':[],'created_at':[],'is_retweet':[],'contains_quote':[],'is_reply':[],'num_referenced_tweets':[],\n",
        "        'url_image':[],'num_hashtags':[],'text_first_hashtag':[],'num_mentions':[],'num_cashtags':[],'num_polls':[]}\n",
        "\n",
        "    if not replies:\n",
        "        outputDict['interaction_score'] = []\n",
        "\n",
        "    token = \"\"\n",
        "    \n",
        "    if paginationToken != None: \n",
        "        token = paginationToken\n",
        "        \n",
        "    # for each page of results\n",
        "    for i in range(math.ceil(numTweets/tweetsPerPage)): \n",
        "        if i != 0 or paginationToken != None:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}, **replyFields}\n",
        "        else:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields, **replyFields}\n",
        "\n",
        "\n",
        "        tweet_json = (send_request(f\"https://api.twitter.com/2/users/{id}/tweets\", params=params))\n",
        "\n",
        "        # handle cases where there is no next page of tweets to grab\n",
        "        try:\n",
        "            token = tweet_json['meta']['next_token']\n",
        "        except: \n",
        "            token = None # in this case, there is no page to grab next.\n",
        "            pass\n",
        "        if token == None:\n",
        "            break\n",
        "\n",
        "        username = tweet_json['includes']['users'][0]['username']\n",
        "        followers = tweet_json['includes']['users'][0]['public_metrics']['followers_count']\n",
        "        \n",
        "        tweetData = tweet_json['data']\n",
        "        for tweet in tweetData:\n",
        "            outputDict['handle'].append(username)\n",
        "            outputDict['followers'].append(followers)\n",
        "            outputDict['id'].append(tweet['id'])\n",
        "            outputDict['text'].append(tweet['text'])\n",
        "            outputDict['lang'].append(tweet['lang'])\n",
        "            outputDict['possibly_sensitive'].append(tweet['possibly_sensitive'])\n",
        "\n",
        "            outputDict['retweet_count'].append(tweet['public_metrics']['retweet_count'])\n",
        "            outputDict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
        "            outputDict['like_count'].append(tweet['public_metrics']['like_count'])\n",
        "            outputDict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
        "            outputDict['reply_settings'].append(tweet['reply_settings'])\n",
        "            outputDict['source'].append(tweet['source'])\n",
        "            outputDict['created_at'].append(tweet['created_at'])\n",
        "\n",
        "            if not replies:\n",
        "                outputDict['interaction_score'].append((weights['retweet'] *outputDict['retweet_count'][-1] + weights['like'] *outputDict['like_count'][-1]+\n",
        "                                                        weights['reply'] *outputDict['reply_count'][-1] + weights['quote'] *outputDict['quote_count'][-1])/followers)\n",
        "\n",
        "            # referenced tweets: quotes, replies, and retweets\n",
        "            try:\n",
        "                refdTweets = tweet['referenced_tweets']\n",
        "                outputDict['num_referenced_tweets'].append(len(refdTweets))\n",
        "\n",
        "                rtweet = False\n",
        "                reply = False\n",
        "                quote = False\n",
        "                # there may be multiple referenced tweets, apparently. So it could be a reply and contain a quote, I guess\n",
        "                for t in refdTweets:\n",
        "                    typ = t['type']\n",
        "                    if typ == 'retweeted':\n",
        "                        outputDict['is_retweet'].append(True)\n",
        "                        rtweet = True\n",
        "                    elif typ == 'quoted':\n",
        "                        outputDict['contains_quote'].append(True)\n",
        "                        quote = True\n",
        "                    elif typ == 'replied_to':\n",
        "                        outputDict['is_reply'].append(True)\n",
        "                        reply = True\n",
        "                        \n",
        "                if not rtweet:\n",
        "                        outputDict['is_retweet'].append(False)\n",
        "                if not reply:\n",
        "                        outputDict['is_reply'].append(False)\n",
        "                if not quote:\n",
        "                        outputDict['contains_quote'].append(False)\n",
        "            except:\n",
        "                outputDict['num_referenced_tweets'].append(0)\n",
        "                outputDict['is_retweet'].append(False)\n",
        "                outputDict['contains_quote'].append(False)\n",
        "                outputDict['is_reply'].append(False)\n",
        "\n",
        "\n",
        "            # image\n",
        "            try:\n",
        "                outputDict['url_image'].append(tweet['entities']['urls'][0]['images'][0]['url'])  #just grabbing the first image in the first url\n",
        "            except:\n",
        "                outputDict['url_image'].append(\"\")\n",
        "\n",
        "            # hashtags\n",
        "            try:\n",
        "                outputDict['num_hashtags'].append(len(tweet['entities']['hashtags']))\n",
        "                # grabbing just the first hashtag\n",
        "                outputDict['text_first_hashtag'].append(tweet['entities']['hashtags'][0]['tag'])\n",
        "            except:\n",
        "                outputDict['num_hashtags'].append(0) \n",
        "                outputDict['text_first_hashtag'].append(\"\")\n",
        "\n",
        "            # mentions\n",
        "            try: outputDict['num_mentions'].append(len(tweet['entities']['mentions']))\n",
        "            except: outputDict['num_mentions'].append(0)\n",
        "\n",
        "            # cashtags\n",
        "            try: outputDict['num_cashtags'].append(len(tweet['entities']['cashtags']))\n",
        "            except: outputDict['num_cashtags'].append(0)\n",
        "            \n",
        "            # polls\n",
        "            try:\n",
        "                outputDict['num_polls'].append(len(tweet['attachments']['poll_ids']))\n",
        "            except:\n",
        "                outputDict['num_polls'].append(0) \n",
        "                pass\n",
        "        \n",
        "    df = pd.DataFrame(outputDict)\n",
        "\n",
        "\n",
        "    return df, token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "qwGZb0eTnvrM"
      },
      "outputs": [],
      "source": [
        "def get_api_data(usernames, replies = False, numTweets = 10, tweetsPerPage = 10, print_status = False):\n",
        "    import time\n",
        "    import traceback\n",
        "    usersDict =  {'following_count':[], 'tweet_count':[], 'followers_count':[], 'listed_count':[], 'handle':[], 'name':[], 'id':[], \n",
        "    'verified': [], 'protected': [],'created_at': [],'description': [], 'hasPinnedTweet':[], 'urlsInDescription':[], 'hashtagsInDescription':[],\n",
        "    'userWebsitesAdded':[], 'cashtagsInDescription':[],'mentionsInDescription':[]}\n",
        "\n",
        "    idDict = {}\n",
        "\n",
        "    for username in usernames:\n",
        "        # get data related to user account\n",
        "        userData = get_user_data(username)\n",
        "        \n",
        "        # create id - username mapping dictionary for use in next loop\n",
        "        idDict[userData['handle']] = userData['id']\n",
        "        \n",
        "        # build the user data dataframe\n",
        "        for k, v in userData.items():\n",
        "            usersDict[k].append(v)\n",
        "\n",
        "    df_user = pd.DataFrame(usersDict)\n",
        "    \n",
        "    if not replies:\n",
        "        #if we are excluding replies, we want to keep pulling until we have at least 500 images\n",
        "        numImages = 0\n",
        "        tokenDict = {}\n",
        "        stopList = []\n",
        "        nextToken = \"\"\n",
        "        firstIteration = True\n",
        "        loopCount = 1\n",
        "        df_tweets = None\n",
        "        while (numImages < 500):\n",
        "            for username in usernames:\n",
        "                # get data from tweets of the user\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if set(stopList) == set(usernames):\n",
        "                    df_tweets.set_index('id', inplace=True)\n",
        "                    df_user.set_index('handle', inplace=True)\n",
        "                    df_tweets.sort_values('handle', inplace=True)\n",
        "                    return df_tweets, df_user\n",
        "                elif stopList.count(username) > 0:\n",
        "                    continue\n",
        "\n",
        "                # if we left off on a page, then jump to the next page of tweet results\n",
        "                try:\n",
        "                    nextToken = tokenDict[username]\n",
        "                    try:\n",
        "                        df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies, paginationToken=nextToken)\n",
        "                    except Exception:\n",
        "                        traceback.print_exc()\n",
        "                except: \n",
        "                    df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)\n",
        "\n",
        "                tokenDict[username] = token\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if token == None:\n",
        "                    stopList.append(username)\n",
        "\n",
        "                if not firstIteration:\n",
        "                    df_tweets = pd.concat([df_tweets, df_sub])\n",
        "                else:\n",
        "                    df_tweets = df_sub\n",
        "                    firstIteration = False\n",
        "                if print_status: \n",
        "                    num_tweets = len(df_sub)\n",
        "                    print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "            numImages = len(df_tweets[df_tweets.url_image != \"\"])\n",
        "            if print_status: print(f\"{loopCount} iterations through while loop. {numImages} images retrieved.\")\n",
        "            # if loopCount % 3 == 0: # if it is a multiple of 3 \n",
        "            #     # we have a limit of 900 requests per 15 minute window.\n",
        "            #     print(\"waiting 5 minutes...\")\n",
        "            #     time.sleep(60*5) # wait 5 minutes\n",
        "            loopCount += 1\n",
        "    else:\n",
        "        df_tweets = None\n",
        "        firstIteration = True\n",
        "        for username in usernames:\n",
        "            # get data from tweets of the user\n",
        "            df_sub = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)[0]\n",
        "\n",
        "            if not firstIteration:\n",
        "                df_tweets = pd.concat([df_tweets, df_sub])\n",
        "            else:\n",
        "                df_tweets = df_sub\n",
        "                firstIteration = False\n",
        "            if print_status: \n",
        "                num_tweets = len(df_sub)\n",
        "                print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "        \n",
        "\n",
        "    df_tweets.set_index('id', inplace=True)\n",
        "    df_user.set_index('handle', inplace=True)\n",
        "    df_tweets.sort_values('handle', inplace=True)\n",
        "\n",
        "    return df_tweets, df_user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Schlotzskys',\n",
              " 'AuntieAnnes',\n",
              " 'SaltgrassSteak',\n",
              " 'redlobster',\n",
              " 'Hardees',\n",
              " 'RuthsChris',\n",
              " 'LongHornSteaks',\n",
              " 'FiveGuys',\n",
              " 'Applebees',\n",
              " 'DelTaco',\n",
              " 'PFChangs',\n",
              " 'BonefishGrill',\n",
              " 'Charleys',\n",
              " 'EinsteinBros',\n",
              " 'qdoba',\n",
              " 'torchystacos',\n",
              " 'raisingcanes',\n",
              " 'Cheesecake',\n",
              " 'WaffleHouse',\n",
              " 'CheckersRallys',\n",
              " 'SmoothieKing',\n",
              " 'CaptainDs',\n",
              " 'WhiteCastle',\n",
              " 'papamurphys',\n",
              " 'caferio',\n",
              " 'ChuysRestaurant',\n",
              " 'ChurchsChicken',\n",
              " 'IHOP',\n",
              " 'BaskinRobbins',\n",
              " 'TSmoothieCafe',\n",
              " 'MODPizza',\n",
              " 'calpizzakitchen',\n",
              " 'FreddysUSA',\n",
              " 'SteaknShake',\n",
              " 'tacojohns',\n",
              " 'Dickeys',\n",
              " 'krispykreme',\n",
              " 'ElPolloLoco',\n",
              " 'ColdStone',\n",
              " 'Whataburger',\n",
              " 'Hooters',\n",
              " 'Maggianos',\n",
              " 'hungryhowies',\n",
              " 'noodlescompany',\n",
              " 'Carrabbas',\n",
              " 'shakeshack',\n",
              " 'jimmyjohns',\n",
              " 'portilloshotdog',\n",
              " 'culvers',\n",
              " 'redrobinburgers',\n",
              " 'goldencorral',\n",
              " 'eatatjacks',\n",
              " 'McAlistersDeli',\n",
              " 'rubytuesday',\n",
              " 'BobEvansFarms',\n",
              " 'CHWinery',\n",
              " 'jasonsdeli',\n",
              " 'longjohnsilvers',\n",
              " 'TGIFridays',\n",
              " 'Potbelly',\n",
              " 'wingstop',\n",
              " 'JambaJuice',\n",
              " 'cheddarskitchen',\n",
              " 'CapitalGrille',\n",
              " 'EatAtPerkins',\n",
              " 'MillersAleHouse',\n",
              " 'JetsPizza',\n",
              " 'ZoesKitchen',\n",
              " 'peetscoffee',\n",
              " 'BlazePizza',\n",
              " 'bostonmarket',\n",
              " 'OCharleys',\n",
              " 'jerseymikes',\n",
              " 'bjsrestaurants',\n",
              " 'Bojangles',\n",
              " 'TimHortons',\n",
              " 'DennysDiner',\n",
              " 'Chilis',\n",
              " 'Outback',\n",
              " 'Moes_HQ',\n",
              " 'FirehouseSubs',\n",
              " 'DutchBros',\n",
              " 'RoundTablePizza',\n",
              " 'pollotropical',\n",
              " 'YardHouse',\n",
              " 'MellowMushroom',\n",
              " 'texasroadhouse',\n",
              " 'olivegarden',\n",
              " 'CrackerBarrel',\n",
              " 'PapaJohns',\n",
              " 'habitburger',\n",
              " 'Zaxbys',\n",
              " 'BWWings',\n",
              " 'MarcosPizza',\n",
              " 'McDonalds',\n",
              " 'Wendys',\n",
              " 'tacobell',\n",
              " 'BurgerKing',\n",
              " 'Arbys',\n",
              " 'Popeyes',\n",
              " 'SUBWAY',\n",
              " 'dominos',\n",
              " 'ChickfilA',\n",
              " 'sonicdrivein',\n",
              " 'kfc',\n",
              " 'Quiznos',\n",
              " 'panerabread',\n",
              " 'ChipotleTweets',\n",
              " 'littlecaesars',\n",
              " 'PandaExpress',\n",
              " 'JackBox',\n",
              " 'Starbucks',\n",
              " 'ShakeysUSA',\n",
              " 'wienerschnitzel',\n",
              " 'JohnnyRockets',\n",
              " 'BajaFresh',\n",
              " 'BurgervilleUSA',\n",
              " 'Cinnabon',\n",
              " 'PitaPitUSA',\n",
              " 'umamiburger',\n",
              " 'kogibbq',\n",
              " 'GrillEmAll',\n",
              " 'MOOYAHBurgers',\n",
              " 'Zippys',\n",
              " 'awrestaurants',\n",
              " 'CarlsJr']"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('fast-food-chains - Sheet1.csv')\n",
        "\n",
        "df.drop(df.columns[0], axis=1, inplace=True)\n",
        "df.loc[df.shape[0]] = df.columns\n",
        "df.columns = [\"handle\"]\n",
        "twitter_handles = df[df.columns[0]].tolist()\n",
        "print(len(twitter_handles))\n",
        "twitter_handles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 80 tweets for: Schlotzskys\n",
            "Retrieved 80 tweets for: AuntieAnnes\n",
            "Retrieved 80 tweets for: SaltgrassSteak\n",
            "Retrieved 80 tweets for: redlobster\n",
            "Retrieved 80 tweets for: Hardees\n",
            "Retrieved 80 tweets for: RuthsChris\n",
            "Retrieved 80 tweets for: LongHornSteaks\n",
            "Retrieved 80 tweets for: FiveGuys\n",
            "Retrieved 80 tweets for: Applebees\n",
            "Retrieved 80 tweets for: DelTaco\n",
            "Retrieved 80 tweets for: PFChangs\n",
            "Retrieved 80 tweets for: BonefishGrill\n",
            "Retrieved 80 tweets for: Charleys\n",
            "Retrieved 80 tweets for: EinsteinBros\n",
            "Retrieved 80 tweets for: qdoba\n",
            "Retrieved 80 tweets for: torchystacos\n",
            "Retrieved 80 tweets for: raisingcanes\n",
            "Retrieved 80 tweets for: Cheesecake\n",
            "Retrieved 80 tweets for: WaffleHouse\n",
            "Retrieved 80 tweets for: CheckersRallys\n",
            "Retrieved 80 tweets for: SmoothieKing\n",
            "Retrieved 80 tweets for: CaptainDs\n",
            "Retrieved 80 tweets for: WhiteCastle\n",
            "Retrieved 80 tweets for: papamurphys\n",
            "Retrieved 80 tweets for: caferio\n",
            "Retrieved 80 tweets for: ChuysRestaurant\n",
            "Retrieved 80 tweets for: ChurchsChicken\n",
            "Retrieved 80 tweets for: IHOP\n",
            "Retrieved 80 tweets for: BaskinRobbins\n",
            "Retrieved 80 tweets for: TSmoothieCafe\n",
            "Retrieved 80 tweets for: MODPizza\n",
            "Retrieved 80 tweets for: calpizzakitchen\n",
            "Retrieved 80 tweets for: FreddysUSA\n",
            "Retrieved 80 tweets for: SteaknShake\n",
            "Retrieved 80 tweets for: tacojohns\n",
            "Retrieved 80 tweets for: Dickeys\n",
            "Retrieved 80 tweets for: krispykreme\n",
            "Retrieved 80 tweets for: ElPolloLoco\n",
            "Retrieved 80 tweets for: ColdStone\n",
            "Retrieved 80 tweets for: Whataburger\n",
            "Retrieved 80 tweets for: Hooters\n",
            "Retrieved 80 tweets for: Maggianos\n",
            "Retrieved 80 tweets for: hungryhowies\n",
            "Retrieved 80 tweets for: noodlescompany\n",
            "Retrieved 80 tweets for: Carrabbas\n",
            "Retrieved 80 tweets for: shakeshack\n",
            "Retrieved 80 tweets for: jimmyjohns\n",
            "Retrieved 80 tweets for: portilloshotdog\n",
            "Retrieved 80 tweets for: culvers\n",
            "Retrieved 80 tweets for: redrobinburgers\n",
            "Retrieved 80 tweets for: goldencorral\n",
            "Retrieved 80 tweets for: eatatjacks\n",
            "Retrieved 80 tweets for: McAlistersDeli\n",
            "Retrieved 80 tweets for: rubytuesday\n",
            "Retrieved 80 tweets for: BobEvansFarms\n",
            "Retrieved 80 tweets for: CHWinery\n",
            "Retrieved 80 tweets for: jasonsdeli\n",
            "Retrieved 80 tweets for: longjohnsilvers\n",
            "Retrieved 80 tweets for: TGIFridays\n",
            "Retrieved 80 tweets for: Potbelly\n",
            "Retrieved 80 tweets for: wingstop\n",
            "Retrieved 80 tweets for: JambaJuice\n",
            "Retrieved 80 tweets for: cheddarskitchen\n",
            "Retrieved 80 tweets for: CapitalGrille\n",
            "Retrieved 80 tweets for: EatAtPerkins\n",
            "Retrieved 80 tweets for: MillersAleHouse\n",
            "Retrieved 80 tweets for: JetsPizza\n",
            "Retrieved 80 tweets for: ZoesKitchen\n",
            "Retrieved 80 tweets for: peetscoffee\n",
            "Retrieved 80 tweets for: BlazePizza\n",
            "Retrieved 79 tweets for: bostonmarket\n",
            "Retrieved 80 tweets for: OCharleys\n",
            "Retrieved 80 tweets for: jerseymikes\n",
            "Retrieved 80 tweets for: bjsrestaurants\n",
            "Retrieved 80 tweets for: Bojangles\n",
            "Retrieved 80 tweets for: TimHortons\n",
            "Retrieved 80 tweets for: DennysDiner\n",
            "Retrieved 80 tweets for: Chilis\n",
            "Retrieved 80 tweets for: Outback\n",
            "Retrieved 80 tweets for: Moes_HQ\n",
            "Retrieved 80 tweets for: FirehouseSubs\n",
            "Retrieved 80 tweets for: DutchBros\n",
            "Retrieved 80 tweets for: RoundTablePizza\n",
            "Retrieved 80 tweets for: pollotropical\n",
            "Retrieved 80 tweets for: YardHouse\n",
            "Retrieved 80 tweets for: MellowMushroom\n",
            "Retrieved 80 tweets for: texasroadhouse\n",
            "Retrieved 80 tweets for: olivegarden\n",
            "Retrieved 80 tweets for: CrackerBarrel\n",
            "Retrieved 80 tweets for: PapaJohns\n",
            "Retrieved 80 tweets for: habitburger\n",
            "Retrieved 80 tweets for: Zaxbys\n",
            "Retrieved 80 tweets for: BWWings\n",
            "Retrieved 80 tweets for: MarcosPizza\n",
            "Retrieved 80 tweets for: McDonalds\n",
            "Retrieved 80 tweets for: Wendys\n",
            "Retrieved 80 tweets for: tacobell\n",
            "Retrieved 80 tweets for: BurgerKing\n",
            "Retrieved 80 tweets for: Arbys\n",
            "Retrieved 80 tweets for: Popeyes\n",
            "Retrieved 80 tweets for: SUBWAY\n",
            "Retrieved 80 tweets for: dominos\n",
            "Retrieved 80 tweets for: ChickfilA\n",
            "Retrieved 80 tweets for: sonicdrivein\n",
            "Retrieved 80 tweets for: kfc\n",
            "Retrieved 80 tweets for: Quiznos\n",
            "Retrieved 80 tweets for: panerabread\n",
            "Retrieved 80 tweets for: ChipotleTweets\n",
            "Retrieved 80 tweets for: littlecaesars\n",
            "Retrieved 79 tweets for: PandaExpress\n",
            "Retrieved 80 tweets for: JackBox\n",
            "Retrieved 80 tweets for: Starbucks\n",
            "Retrieved 80 tweets for: ShakeysUSA\n",
            "Retrieved 80 tweets for: wienerschnitzel\n",
            "Retrieved 80 tweets for: JohnnyRockets\n",
            "Retrieved 80 tweets for: BajaFresh\n",
            "Retrieved 80 tweets for: BurgervilleUSA\n",
            "Retrieved 80 tweets for: Cinnabon\n",
            "Retrieved 80 tweets for: PitaPitUSA\n",
            "Retrieved 80 tweets for: umamiburger\n",
            "Retrieved 80 tweets for: kogibbq\n",
            "Retrieved 80 tweets for: GrillEmAll\n",
            "Retrieved 80 tweets for: MOOYAHBurgers\n",
            "Retrieved 80 tweets for: Zippys\n",
            "Retrieved 80 tweets for: awrestaurants\n",
            "Retrieved 80 tweets for: CarlsJr\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 299 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 300 tweets for: Hardees\n",
            "Retrieved 300 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 299 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 297 tweets for: BonefishGrill\n",
            "Retrieved 296 tweets for: Charleys\n",
            "Retrieved 296 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 300 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 300 tweets for: WaffleHouse\n",
            "Retrieved 298 tweets for: CheckersRallys\n",
            "Retrieved 300 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 299 tweets for: WhiteCastle\n",
            "Retrieved 300 tweets for: papamurphys\n",
            "Retrieved 300 tweets for: caferio\n",
            "Retrieved 300 tweets for: ChuysRestaurant\n",
            "Retrieved 296 tweets for: ChurchsChicken\n",
            "Retrieved 300 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 300 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 300 tweets for: tacojohns\n",
            "Retrieved 300 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 298 tweets for: ElPolloLoco\n",
            "Retrieved 299 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 299 tweets for: Maggianos\n",
            "Retrieved 296 tweets for: hungryhowies\n",
            "Retrieved 300 tweets for: noodlescompany\n",
            "Retrieved 299 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 298 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 296 tweets for: redrobinburgers\n",
            "Retrieved 300 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 299 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 299 tweets for: jasonsdeli\n",
            "Retrieved 295 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 299 tweets for: Potbelly\n",
            "Retrieved 300 tweets for: wingstop\n",
            "Retrieved 300 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 297 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 298 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 300 tweets for: BlazePizza\n",
            "Retrieved 298 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 300 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 299 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 298 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 299 tweets for: RoundTablePizza\n",
            "Retrieved 299 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 300 tweets for: MellowMushroom\n",
            "Retrieved 295 tweets for: texasroadhouse\n",
            "Retrieved 300 tweets for: olivegarden\n",
            "Retrieved 300 tweets for: CrackerBarrel\n",
            "Retrieved 299 tweets for: PapaJohns\n",
            "Retrieved 300 tweets for: habitburger\n",
            "Retrieved 300 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 299 tweets for: MarcosPizza\n",
            "Retrieved 300 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: Wendys\n",
            "Retrieved 300 tweets for: tacobell\n",
            "Retrieved 300 tweets for: BurgerKing\n",
            "Retrieved 300 tweets for: Arbys\n",
            "Retrieved 300 tweets for: Popeyes\n",
            "Retrieved 300 tweets for: SUBWAY\n",
            "Retrieved 300 tweets for: dominos\n",
            "Retrieved 300 tweets for: ChickfilA\n",
            "Retrieved 300 tweets for: sonicdrivein\n",
            "Retrieved 300 tweets for: kfc\n",
            "Retrieved 300 tweets for: Quiznos\n",
            "Retrieved 299 tweets for: panerabread\n",
            "Retrieved 298 tweets for: ChipotleTweets\n",
            "Retrieved 300 tweets for: littlecaesars\n",
            "Retrieved 299 tweets for: PandaExpress\n",
            "Retrieved 300 tweets for: JackBox\n",
            "Retrieved 297 tweets for: Starbucks\n",
            "Retrieved 300 tweets for: ShakeysUSA\n",
            "Retrieved 300 tweets for: wienerschnitzel\n",
            "Retrieved 300 tweets for: JohnnyRockets\n",
            "Retrieved 300 tweets for: BajaFresh\n",
            "Retrieved 290 tweets for: BurgervilleUSA\n",
            "Retrieved 299 tweets for: Cinnabon\n",
            "Retrieved 299 tweets for: PitaPitUSA\n",
            "Retrieved 300 tweets for: umamiburger\n",
            "Retrieved 300 tweets for: kogibbq\n",
            "Retrieved 298 tweets for: GrillEmAll\n",
            "Retrieved 294 tweets for: MOOYAHBurgers\n",
            "Retrieved 300 tweets for: Zippys\n",
            "Retrieved 298 tweets for: awrestaurants\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "1 iterations through while loop. 355 images retrieved.\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 300 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 297 tweets for: Hardees\n",
            "Retrieved 299 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 300 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 296 tweets for: BonefishGrill\n",
            "Retrieved 292 tweets for: Charleys\n",
            "Retrieved 299 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 299 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 298 tweets for: WaffleHouse\n",
            "Retrieved 299 tweets for: CheckersRallys\n",
            "Retrieved 298 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 300 tweets for: WhiteCastle\n",
            "Retrieved 293 tweets for: papamurphys\n",
            "Retrieved 297 tweets for: caferio\n",
            "Retrieved 299 tweets for: ChuysRestaurant\n",
            "Retrieved 297 tweets for: ChurchsChicken\n",
            "Retrieved 298 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 298 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 296 tweets for: tacojohns\n",
            "Retrieved 299 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 300 tweets for: ElPolloLoco\n",
            "Retrieved 297 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 298 tweets for: Maggianos\n",
            "Retrieved 298 tweets for: hungryhowies\n",
            "Retrieved 299 tweets for: noodlescompany\n",
            "Retrieved 292 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 299 tweets for: redrobinburgers\n",
            "Retrieved 289 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 284 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 297 tweets for: jasonsdeli\n",
            "Retrieved 282 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 277 tweets for: Potbelly\n",
            "Retrieved 298 tweets for: wingstop\n",
            "Retrieved 299 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 298 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 299 tweets for: BlazePizza\n",
            "Retrieved 300 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 298 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 300 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 300 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 300 tweets for: RoundTablePizza\n",
            "Retrieved 300 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 297 tweets for: MellowMushroom\n",
            "Retrieved 293 tweets for: texasroadhouse\n",
            "Retrieved 299 tweets for: olivegarden\n",
            "Retrieved 298 tweets for: CrackerBarrel\n",
            "Retrieved 300 tweets for: PapaJohns\n",
            "Retrieved 299 tweets for: habitburger\n",
            "Retrieved 297 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 298 tweets for: MarcosPizza\n",
            "Retrieved 299 tweets for: McDonalds\n",
            "Retrieved 299 tweets for: Wendys\n",
            "Retrieved 299 tweets for: tacobell\n",
            "Retrieved 300 tweets for: BurgerKing\n",
            "Retrieved 298 tweets for: Arbys\n",
            "Retrieved 299 tweets for: Popeyes\n",
            "Retrieved 300 tweets for: SUBWAY\n",
            "Retrieved 300 tweets for: dominos\n",
            "Retrieved 300 tweets for: ChickfilA\n",
            "Retrieved 300 tweets for: sonicdrivein\n",
            "Retrieved 297 tweets for: kfc\n",
            "Retrieved 300 tweets for: Quiznos\n",
            "Retrieved 300 tweets for: panerabread\n",
            "Retrieved 297 tweets for: ChipotleTweets\n",
            "Retrieved 300 tweets for: littlecaesars\n",
            "Retrieved 299 tweets for: PandaExpress\n",
            "Retrieved 299 tweets for: JackBox\n",
            "Retrieved 297 tweets for: Starbucks\n",
            "Retrieved 300 tweets for: ShakeysUSA\n",
            "Retrieved 299 tweets for: wienerschnitzel\n",
            "Retrieved 299 tweets for: JohnnyRockets\n",
            "Retrieved 294 tweets for: BajaFresh\n",
            "Retrieved 291 tweets for: BurgervilleUSA\n",
            "Retrieved 299 tweets for: Cinnabon\n",
            "Retrieved 297 tweets for: PitaPitUSA\n",
            "Retrieved 300 tweets for: umamiburger\n",
            "Retrieved 300 tweets for: kogibbq\n",
            "Retrieved 299 tweets for: GrillEmAll\n",
            "Retrieved 287 tweets for: MOOYAHBurgers\n",
            "Retrieved 300 tweets for: Zippys\n",
            "Retrieved 299 tweets for: awrestaurants\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "2 iterations through while loop. 470 images retrieved.\n",
            "Retrieved 200 tweets for: Schlotzskys\n",
            "Retrieved 191 tweets for: AuntieAnnes\n",
            "Retrieved 200 tweets for: SaltgrassSteak\n",
            "Retrieved 200 tweets for: redlobster\n",
            "Retrieved 200 tweets for: Hardees\n",
            "Retrieved 191 tweets for: RuthsChris\n",
            "Retrieved 200 tweets for: LongHornSteaks\n",
            "Retrieved 199 tweets for: FiveGuys\n",
            "Retrieved 200 tweets for: Applebees\n",
            "Retrieved 200 tweets for: DelTaco\n",
            "Retrieved 200 tweets for: PFChangs\n",
            "Retrieved 195 tweets for: BonefishGrill\n",
            "Retrieved 200 tweets for: Charleys\n",
            "Retrieved 186 tweets for: EinsteinBros\n",
            "Retrieved 200 tweets for: qdoba\n",
            "Retrieved 198 tweets for: torchystacos\n",
            "Retrieved 200 tweets for: raisingcanes\n",
            "Retrieved 200 tweets for: Cheesecake\n",
            "Retrieved 196 tweets for: WaffleHouse\n",
            "Retrieved 198 tweets for: CheckersRallys\n",
            "Retrieved 200 tweets for: SmoothieKing\n",
            "Retrieved 199 tweets for: CaptainDs\n",
            "Retrieved 200 tweets for: WhiteCastle\n",
            "Retrieved 198 tweets for: papamurphys\n",
            "Retrieved 196 tweets for: caferio\n",
            "Retrieved 197 tweets for: ChuysRestaurant\n",
            "Retrieved 200 tweets for: ChurchsChicken\n",
            "Retrieved 200 tweets for: IHOP\n",
            "Retrieved 200 tweets for: BaskinRobbins\n",
            "Retrieved 185 tweets for: TSmoothieCafe\n",
            "Retrieved 200 tweets for: MODPizza\n",
            "Retrieved 199 tweets for: calpizzakitchen\n",
            "Retrieved 196 tweets for: FreddysUSA\n",
            "Retrieved 200 tweets for: SteaknShake\n",
            "Retrieved 197 tweets for: tacojohns\n",
            "Retrieved 200 tweets for: Dickeys\n",
            "Retrieved 200 tweets for: krispykreme\n",
            "Retrieved 200 tweets for: ElPolloLoco\n",
            "Retrieved 199 tweets for: ColdStone\n",
            "Retrieved 199 tweets for: Whataburger\n",
            "Retrieved 200 tweets for: Hooters\n",
            "Retrieved 200 tweets for: Maggianos\n",
            "Retrieved 200 tweets for: hungryhowies\n",
            "Retrieved 199 tweets for: noodlescompany\n",
            "Retrieved 197 tweets for: Carrabbas\n",
            "Retrieved 200 tweets for: shakeshack\n",
            "Retrieved 190 tweets for: jimmyjohns\n",
            "Retrieved 197 tweets for: portilloshotdog\n",
            "Retrieved 200 tweets for: culvers\n",
            "Retrieved 200 tweets for: redrobinburgers\n",
            "Retrieved 189 tweets for: goldencorral\n",
            "Retrieved 198 tweets for: eatatjacks\n",
            "Retrieved 200 tweets for: McAlistersDeli\n",
            "Retrieved 200 tweets for: rubytuesday\n",
            "Retrieved 84 tweets for: BobEvansFarms\n",
            "Retrieved 198 tweets for: CHWinery\n",
            "Retrieved 200 tweets for: jasonsdeli\n",
            "Retrieved 191 tweets for: longjohnsilvers\n",
            "Retrieved 200 tweets for: TGIFridays\n",
            "Retrieved 185 tweets for: Potbelly\n",
            "Retrieved 200 tweets for: wingstop\n",
            "Retrieved 198 tweets for: JambaJuice\n",
            "Retrieved 198 tweets for: cheddarskitchen\n",
            "Retrieved 199 tweets for: CapitalGrille\n",
            "Retrieved 197 tweets for: EatAtPerkins\n",
            "Retrieved 199 tweets for: MillersAleHouse\n",
            "Retrieved 198 tweets for: JetsPizza\n",
            "Retrieved 192 tweets for: ZoesKitchen\n",
            "Retrieved 199 tweets for: peetscoffee\n",
            "Retrieved 200 tweets for: BlazePizza\n",
            "Retrieved 200 tweets for: bostonmarket\n",
            "Retrieved 194 tweets for: OCharleys\n",
            "Retrieved 198 tweets for: jerseymikes\n",
            "Retrieved 200 tweets for: bjsrestaurants\n",
            "Retrieved 200 tweets for: Bojangles\n",
            "Retrieved 200 tweets for: TimHortons\n",
            "Retrieved 200 tweets for: DennysDiner\n",
            "Retrieved 200 tweets for: Chilis\n",
            "Retrieved 199 tweets for: Outback\n",
            "Retrieved 200 tweets for: Moes_HQ\n",
            "Retrieved 200 tweets for: FirehouseSubs\n",
            "Retrieved 194 tweets for: DutchBros\n",
            "Retrieved 199 tweets for: RoundTablePizza\n",
            "Retrieved 200 tweets for: pollotropical\n",
            "Retrieved 200 tweets for: YardHouse\n",
            "Retrieved 195 tweets for: MellowMushroom\n",
            "Retrieved 199 tweets for: texasroadhouse\n",
            "Retrieved 199 tweets for: olivegarden\n",
            "Retrieved 200 tweets for: CrackerBarrel\n",
            "Retrieved 200 tweets for: PapaJohns\n",
            "Retrieved 200 tweets for: habitburger\n",
            "Retrieved 193 tweets for: Zaxbys\n",
            "Retrieved 199 tweets for: BWWings\n",
            "Retrieved 194 tweets for: MarcosPizza\n",
            "Retrieved 199 tweets for: McDonalds\n",
            "Retrieved 200 tweets for: Wendys\n",
            "Retrieved 200 tweets for: tacobell\n",
            "Retrieved 200 tweets for: BurgerKing\n",
            "Retrieved 196 tweets for: Arbys\n",
            "Retrieved 200 tweets for: Popeyes\n",
            "Retrieved 200 tweets for: SUBWAY\n",
            "Retrieved 200 tweets for: dominos\n",
            "Retrieved 199 tweets for: ChickfilA\n",
            "Retrieved 198 tweets for: sonicdrivein\n",
            "Retrieved 197 tweets for: kfc\n",
            "Retrieved 198 tweets for: Quiznos\n",
            "Retrieved 196 tweets for: panerabread\n",
            "Retrieved 194 tweets for: ChipotleTweets\n",
            "Retrieved 190 tweets for: littlecaesars\n",
            "Retrieved 200 tweets for: PandaExpress\n",
            "Retrieved 198 tweets for: JackBox\n",
            "Retrieved 196 tweets for: Starbucks\n",
            "Retrieved 200 tweets for: ShakeysUSA\n",
            "Retrieved 199 tweets for: wienerschnitzel\n",
            "Retrieved 200 tweets for: JohnnyRockets\n",
            "Retrieved 185 tweets for: BajaFresh\n",
            "Retrieved 192 tweets for: BurgervilleUSA\n",
            "Retrieved 200 tweets for: Cinnabon\n",
            "Retrieved 100 tweets for: PitaPitUSA\n",
            "Retrieved 200 tweets for: umamiburger\n",
            "Retrieved 200 tweets for: kogibbq\n",
            "Retrieved 200 tweets for: GrillEmAll\n",
            "Retrieved 192 tweets for: MOOYAHBurgers\n",
            "Retrieved 200 tweets for: Zippys\n",
            "Retrieved 198 tweets for: awrestaurants\n",
            "Retrieved 199 tweets for: CarlsJr\n",
            "3 iterations through while loop. 509 images retrieved.\n"
          ]
        }
      ],
      "source": [
        "reply_tweetDf, userDf = get_api_data(twitter_handles, replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "noreply_tweetDf, userDf = get_api_data(twitter_handles, replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)\n",
        "\n",
        "# reply_tweetDf, userDf = get_api_data(['McDonalds'], replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "# noreply_tweetDf, userDf = get_api_data(['McDonalds', 'RuthsChris'], replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99993"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handle</th>\n",
              "      <th>followers</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_settings</th>\n",
              "      <th>...</th>\n",
              "      <th>contains_quote</th>\n",
              "      <th>is_reply</th>\n",
              "      <th>num_referenced_tweets</th>\n",
              "      <th>url_image</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>text_first_hashtag</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>num_cashtags</th>\n",
              "      <th>num_polls</th>\n",
              "      <th>interaction_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1221160812389203969</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>Hurry in before the blue moon is gone. Not tha...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106316070821003265</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>cool me neither</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106314060310679552</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>have you ever thought about how reading out lo...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106311542570713089</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>so did St. Patrick like...invent beer?</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>79</td>\n",
              "      <td>4</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106309275612311552</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>Once I found a three-leaf clover, and then I g...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228406806805909504</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263466</td>\n",
              "      <td>RT @wingstop: @Doordash You have our heart, mi...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>BeOurBrandValentine</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228405530563092488</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263466</td>\n",
              "      <td>#Valentinesday isnt complete without Wings in...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>91</td>\n",
              "      <td>3</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>Valentinesday</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228399425615208448</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263466</td>\n",
              "      <td>RT @wingstop: Today were shooting our shot, s...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>BeOurBrandValentine</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232792065056047110</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263466</td>\n",
              "      <td>Our bags hold a lot of stuff if you need some ...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>139</td>\n",
              "      <td>3</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220511563016278017</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263466</td>\n",
              "      <td>Get you a Wing who can do it all  https://t.c...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>57</td>\n",
              "      <td>9</td>\n",
              "      <td>336</td>\n",
              "      <td>10</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99993 rows  23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        handle  followers  \\\n",
              "id                                          \n",
              "1221160812389203969  Applebees     599611   \n",
              "1106316070821003265  Applebees     599611   \n",
              "1106314060310679552  Applebees     599611   \n",
              "1106311542570713089  Applebees     599611   \n",
              "1106309275612311552  Applebees     599611   \n",
              "...                        ...        ...   \n",
              "1228406806805909504   wingstop     263466   \n",
              "1228405530563092488   wingstop     263466   \n",
              "1228399425615208448   wingstop     263466   \n",
              "1232792065056047110   wingstop     263466   \n",
              "1220511563016278017   wingstop     263466   \n",
              "\n",
              "                                                                  text lang  \\\n",
              "id                                                                            \n",
              "1221160812389203969  Hurry in before the blue moon is gone. Not tha...   en   \n",
              "1106316070821003265                                    cool me neither   en   \n",
              "1106314060310679552  have you ever thought about how reading out lo...   en   \n",
              "1106311542570713089             so did St. Patrick like...invent beer?   en   \n",
              "1106309275612311552  Once I found a three-leaf clover, and then I g...   en   \n",
              "...                                                                ...  ...   \n",
              "1228406806805909504  RT @wingstop: @Doordash You have our heart, mi...   en   \n",
              "1228405530563092488  #Valentinesday isnt complete without Wings in...   en   \n",
              "1228399425615208448  RT @wingstop: Today were shooting our shot, s...   en   \n",
              "1232792065056047110  Our bags hold a lot of stuff if you need some ...   en   \n",
              "1220511563016278017  Get you a Wing who can do it all  https://t.c...   en   \n",
              "\n",
              "                     possibly_sensitive  retweet_count  reply_count  \\\n",
              "id                                                                    \n",
              "1221160812389203969               False              7           11   \n",
              "1106316070821003265               False             23            4   \n",
              "1106314060310679552               False              7            4   \n",
              "1106311542570713089               False             20            3   \n",
              "1106309275612311552               False              7            3   \n",
              "...                                 ...            ...          ...   \n",
              "1228406806805909504               False              4            0   \n",
              "1228405530563092488               False             19            6   \n",
              "1228399425615208448               False             15            0   \n",
              "1232792065056047110               False             17            6   \n",
              "1220511563016278017               False             57            9   \n",
              "\n",
              "                     like_count  quote_count reply_settings  ...  \\\n",
              "id                                                           ...   \n",
              "1221160812389203969          49            1       everyone  ...   \n",
              "1106316070821003265          63            3       everyone  ...   \n",
              "1106314060310679552          50            2       everyone  ...   \n",
              "1106311542570713089          79            4       everyone  ...   \n",
              "1106309275612311552          47            3       everyone  ...   \n",
              "...                         ...          ...            ...  ...   \n",
              "1228406806805909504           0            0       everyone  ...   \n",
              "1228405530563092488          91            3       everyone  ...   \n",
              "1228399425615208448           0            0       everyone  ...   \n",
              "1232792065056047110         139            3       everyone  ...   \n",
              "1220511563016278017         336           10       everyone  ...   \n",
              "\n",
              "                    contains_quote is_reply  num_referenced_tweets  url_image  \\\n",
              "id                                                                              \n",
              "1221160812389203969          False    False                      0              \n",
              "1106316070821003265          False    False                      0              \n",
              "1106314060310679552          False    False                      0              \n",
              "1106311542570713089          False    False                      0              \n",
              "1106309275612311552          False    False                      0              \n",
              "...                            ...      ...                    ...        ...   \n",
              "1228406806805909504          False    False                      1              \n",
              "1228405530563092488           True    False                      1              \n",
              "1228399425615208448          False    False                      1              \n",
              "1232792065056047110           True    False                      1              \n",
              "1220511563016278017          False    False                      0              \n",
              "\n",
              "                     num_hashtags   text_first_hashtag num_mentions  \\\n",
              "id                                                                    \n",
              "1221160812389203969             0                                 0   \n",
              "1106316070821003265             0                                 0   \n",
              "1106314060310679552             0                                 0   \n",
              "1106311542570713089             0                                 0   \n",
              "1106309275612311552             0                                 0   \n",
              "...                           ...                  ...          ...   \n",
              "1228406806805909504             1  BeOurBrandValentine            2   \n",
              "1228405530563092488             2        Valentinesday            0   \n",
              "1228399425615208448             1  BeOurBrandValentine            1   \n",
              "1232792065056047110             0                                 0   \n",
              "1220511563016278017             0                                 0   \n",
              "\n",
              "                     num_cashtags num_polls  interaction_score  \n",
              "id                                                              \n",
              "1221160812389203969             0         0           0.000101  \n",
              "1106316070821003265             0         0           0.000194  \n",
              "1106314060310679552             0         0           0.000097  \n",
              "1106311542570713089             0         0           0.000198  \n",
              "1106309275612311552             0         0           0.000099  \n",
              "...                           ...       ...                ...  \n",
              "1228406806805909504             0         0           0.000046  \n",
              "1228405530563092488             0         0           0.000457  \n",
              "1228399425615208448             0         0           0.000171  \n",
              "1232792065056047110             0         0           0.000526  \n",
              "1220511563016278017             0         0           0.001473  \n",
              "\n",
              "[99993 rows x 23 columns]"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "noreply_tweetDf.to_csv('noReplies.csv')\n",
        "reply_tweetDf.to_csv('replies.csv')\n",
        "userDf.to_csv('userData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qdoba 800\n",
            "redlobster 800\n",
            "bjsrestaurants 800\n",
            "Zippys 800\n",
            "culvers 800\n",
            "dominos 800\n",
            "Hooters 800\n",
            "DennysDiner 800\n",
            "YardHouse 800\n",
            "kogibbq 800\n",
            "krispykreme 800\n",
            "TimHortons 800\n",
            "Chilis 800\n",
            "LongHornSteaks 800\n",
            "Cheesecake 800\n",
            "raisingcanes 800\n",
            "FirehouseSubs 800\n",
            "TGIFridays 800\n",
            "Schlotzskys 800\n",
            "PFChangs 800\n",
            "Moes_HQ 800\n",
            "umamiburger 800\n",
            "BaskinRobbins 800\n",
            "SUBWAY 800\n",
            "SaltgrassSteak 800\n",
            "McAlistersDeli 800\n",
            "BurgerKing 800\n",
            "shakeshack 800\n",
            "rubytuesday 800\n",
            "ShakeysUSA 800\n",
            "SteaknShake 800\n",
            "FiveGuys 799\n",
            "WhiteCastle 799\n",
            "Wendys 799\n",
            "JohnnyRockets 799\n",
            "Applebees 799\n",
            "Dickeys 799\n",
            "CaptainDs 799\n",
            "ChickfilA 799\n",
            "BWWings 799\n",
            "BlazePizza 799\n",
            "tacobell 799\n",
            "Bojangles 799\n",
            "CapitalGrille 799\n",
            "calpizzakitchen 799\n",
            "CarlsJr 799\n",
            "Popeyes 799\n",
            "pollotropical 799\n",
            "habitburger 799\n",
            "PapaJohns 799\n",
            "olivegarden 798\n",
            "SmoothieKing 798\n",
            "noodlescompany 798\n",
            "sonicdrivein 798\n",
            "eatatjacks 798\n",
            "cheddarskitchen 798\n",
            "RoundTablePizza 798\n",
            "Quiznos 798\n",
            "wienerschnitzel 798\n",
            "bostonmarket 798\n",
            "wingstop 798\n",
            "DelTaco 798\n",
            "PandaExpress 798\n",
            "JetsPizza 798\n",
            "IHOP 798\n",
            "MODPizza 798\n",
            "ElPolloLoco 798\n",
            "McDonalds 798\n",
            "CrackerBarrel 798\n",
            "Cinnabon 798\n",
            "CHWinery 798\n",
            "Whataburger 797\n",
            "EatAtPerkins 797\n",
            "GrillEmAll 797\n",
            "Hardees 797\n",
            "peetscoffee 797\n",
            "portilloshotdog 797\n",
            "JackBox 797\n",
            "torchystacos 797\n",
            "JambaJuice 797\n",
            "Maggianos 797\n",
            "Outback 797\n",
            "ChuysRestaurant 796\n",
            "jerseymikes 796\n",
            "jasonsdeli 796\n",
            "redrobinburgers 795\n",
            "CheckersRallys 795\n",
            "panerabread 795\n",
            "ColdStone 795\n",
            "awrestaurants 795\n",
            "kfc 794\n",
            "Arbys 794\n",
            "OCharleys 794\n",
            "MillersAleHouse 794\n",
            "hungryhowies 794\n",
            "FreddysUSA 794\n",
            "WaffleHouse 794\n",
            "caferio 793\n",
            "tacojohns 793\n",
            "ChurchsChicken 793\n",
            "MellowMushroom 792\n",
            "MarcosPizza 791\n",
            "papamurphys 791\n",
            "DutchBros 790\n",
            "RuthsChris 790\n",
            "littlecaesars 790\n",
            "AuntieAnnes 790\n",
            "Starbucks 790\n",
            "Zaxbys 790\n",
            "ChipotleTweets 789\n",
            "BonefishGrill 788\n",
            "Charleys 788\n",
            "Carrabbas 788\n",
            "texasroadhouse 787\n",
            "ZoesKitchen 787\n",
            "jimmyjohns 785\n",
            "TSmoothieCafe 785\n",
            "EinsteinBros 781\n",
            "BajaFresh 779\n",
            "goldencorral 778\n",
            "BurgervilleUSA 773\n",
            "MOOYAHBurgers 773\n",
            "longjohnsilvers 768\n",
            "Potbelly 761\n",
            "PitaPitUSA 696\n",
            "BobEvansFarms 667\n"
          ]
        }
      ],
      "source": [
        "for name, count in noreply_tweetDf.handle.value_counts().items():\n",
        "    print(f\"{name} {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "509"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(noreply_tweetDf[noreply_tweetDf.url_image != \"\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "455-final-project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
