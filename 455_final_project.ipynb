{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 621,
      "metadata": {
        "id": "UekkzUwDavf2"
      },
      "outputs": [],
      "source": [
        "# ### Mount Drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 622,
      "metadata": {
        "id": "HfSN7hb4aphV"
      },
      "outputs": [],
      "source": [
        "### Imports\n",
        "\n",
        "import os, requests, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 623,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Constants\n",
        "\n",
        "WEIGHTS = {\"retweet\" : 3, \"like\" : 0.5 ,\"quote\" : 4 ,\"reply\" : 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Requests functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 624,
      "metadata": {
        "id": "2k1VI619aNhd"
      },
      "outputs": [],
      "source": [
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAEqDUAEAAAAAPylQ7hO%2FoW9BuUjtiG608qAZJPg%3DKHFGBs8PtUg49u2TBLzina1UcfwkGtNuCJHlT55omuPiLUaIyi\"\n",
        "\n",
        "def response_health(r):\n",
        "  if r.status_code != 200:\n",
        "    raise Exception(\n",
        "    \"Request returned an error: {} {}\".format(\n",
        "      r.status_code, r.text\n",
        "    )\n",
        "  )\n",
        "    \n",
        "def bearer_oauth(r):\n",
        "  r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "  return r\n",
        "\n",
        "def send_request(url, params=None, print_status=False):\n",
        "  '''Send Request (url) with optional params. Returns json'''\n",
        "  # https://2.python-requests.org/en/master/api/#requests.request\n",
        "  if params == None:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
        "  else:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
        "  if print_status: print(\"Request response status: \", response.status_code)\n",
        "  response_health(response)\n",
        "  return response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Twitter api functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 625,
      "metadata": {
        "id": "VvapD2RKjCuA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_fast_food_handles():\n",
        "    df = pd.read_csv('fast-food-chains - Sheet1.csv')\n",
        "    df.drop(df.columns[0], axis=1, inplace=True)\n",
        "    df.loc[df.shape[0]] = df.columns\n",
        "    df.columns = [\"handle\"]\n",
        "    twitter_handles = df[df.columns[0]].tolist()\n",
        "    return twitter_handles\n",
        "\n",
        "def get_user_data(name):\n",
        "  # data dictionary scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
        "\n",
        "  userFields = {\"user.fields\":\"created_at, description, entities, id, location, name, pinned_tweet_id, profile_image_url, protected, public_metrics, url, username, verified, withheld\".replace(\" \", \"\")}\n",
        "  user_json = send_request(f\"https://api.twitter.com/2/users/by/username/{name}\",params=userFields)\n",
        "  user_json = user_json[\"data\"]\n",
        "\n",
        "  outputDict = {}\n",
        "  outputDict['following_count'] = user_json['public_metrics']['following_count']\n",
        "  outputDict['tweet_count'] = user_json['public_metrics']['tweet_count']\n",
        "  outputDict['followers_count'] = user_json['public_metrics']['followers_count']\n",
        "  outputDict['listed_count'] = user_json['public_metrics']['listed_count']\n",
        "  outputDict['handle'] = user_json['username']\n",
        "  outputDict['name'] = user_json['name']\n",
        "  outputDict['id'] = user_json['id']\n",
        "  outputDict['verified'] = user_json['verified']\n",
        "  outputDict['protected'] = user_json['protected']\n",
        "  outputDict['created_at'] = user_json['created_at']\n",
        "  outputDict['description'] = user_json['description']\n",
        "\n",
        "  try:\n",
        "    test = user_json['pinned_tweet_id']\n",
        "    outputDict['hasPinnedTweet'] = True\n",
        "  except:\n",
        "    outputDict['hasPinnedTweet'] = False\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['urlsInDescription'] = len(user_json['entities']['description']['urls'])\n",
        "  except:\n",
        "    outputDict['urlsInDescription'] = 0\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['hashtagsInDescription'] = len(user_json['entities']['description']['hashtags'])\n",
        "  except:\n",
        "    outputDict['hashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['userWebsitesAdded'] = len(user_json['entities']['url']['urls'])\n",
        "  except:\n",
        "    outputDict['userWebsitesAdded'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['cashtagsInDescription'] = len(user_json['entities']['description']['cashtags'])\n",
        "  except:\n",
        "    outputDict['cashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['mentionsInDescription'] = len(user_json['entities']['description']['mentions'])\n",
        "  except:\n",
        "    outputDict['mentionsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  \n",
        "  return outputDict\n",
        "\n",
        "def get_tweets_user(id, numTweets = 10, tweetsPerPage = 10, replies = False, weights=WEIGHTS, paginationToken = None):\n",
        "    import math\n",
        "    \n",
        "    # (there are 10 results returned per page by default)\n",
        "    if numTweets < tweetsPerPage:\n",
        "        print(\"numTweets must be greater than or equal to the number of tweets per page.\")\n",
        "        return\n",
        "\n",
        "    # to see data dictionary, click url and scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
        "    expansions = {\"expansions\":\"author_id, attachments.poll_ids, attachments.media_keys, entities.mentions.username, geo.place_id, in_reply_to_user_id, referenced_tweets.id,referenced_tweets.id.author_id\".replace(\" \", \"\")}\n",
        "    tweetFields = {\"tweet.fields\":\"attachments, author_id, context_annotations, conversation_id, created_at, entities, geo, id, in_reply_to_user_id, lang, public_metrics, possibly_sensitive, referenced_tweets, reply_settings, source, text, withheld\".replace(\" \", \"\")}\n",
        "    userFields = {\"user.fields\":\"public_metrics,username\"}\n",
        "    replyFields = {\"exclude\": \"replies\"}\n",
        "\n",
        "    outputDict = {'id':[],'handle':[],'followers':[], 'text':[], 'lang':[],'possibly_sensitive':[],'retweet_count':[],'reply_count':[],'like_count':[],'quote_count':[]\n",
        "        ,'reply_settings':[],'source':[],'created_at':[],'is_retweet':[],'contains_quote':[],'is_reply':[],'num_referenced_tweets':[],\n",
        "        'url_image':[],'num_hashtags':[],'text_first_hashtag':[],'num_mentions':[],'num_cashtags':[],'num_polls':[]}\n",
        "\n",
        "    if not replies:\n",
        "        outputDict['interaction_score'] = []\n",
        "\n",
        "    token = \"\"\n",
        "    \n",
        "    if paginationToken != None: \n",
        "        token = paginationToken\n",
        "        \n",
        "    # for each page of results\n",
        "    for i in range(math.ceil(numTweets/tweetsPerPage)): \n",
        "        if i != 0 or paginationToken != None:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}, **replyFields}\n",
        "        else:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields, **replyFields}\n",
        "\n",
        "\n",
        "        tweet_json = (send_request(f\"https://api.twitter.com/2/users/{id}/tweets\", params=params))\n",
        "\n",
        "        # handle cases where there is no next page of tweets to grab\n",
        "        try:\n",
        "            token = tweet_json['meta']['next_token']\n",
        "        except: \n",
        "            token = None # in this case, there is no page to grab next.\n",
        "            pass\n",
        "        if token == None:\n",
        "            break\n",
        "\n",
        "        username = tweet_json['includes']['users'][0]['username']\n",
        "        followers = tweet_json['includes']['users'][0]['public_metrics']['followers_count']\n",
        "        \n",
        "        tweetData = tweet_json['data']\n",
        "        for tweet in tweetData:\n",
        "            outputDict['handle'].append(username)\n",
        "            outputDict['followers'].append(followers)\n",
        "            outputDict['id'].append(tweet['id'])\n",
        "            outputDict['text'].append(tweet['text'])\n",
        "            outputDict['lang'].append(tweet['lang'])\n",
        "            outputDict['possibly_sensitive'].append(tweet['possibly_sensitive'])\n",
        "\n",
        "            outputDict['retweet_count'].append(tweet['public_metrics']['retweet_count'])\n",
        "            outputDict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
        "            outputDict['like_count'].append(tweet['public_metrics']['like_count'])\n",
        "            outputDict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
        "            outputDict['reply_settings'].append(tweet['reply_settings'])\n",
        "            outputDict['source'].append(tweet['source'])\n",
        "            outputDict['created_at'].append(tweet['created_at'])\n",
        "\n",
        "            if not replies:\n",
        "                outputDict['interaction_score'].append((weights['retweet'] *outputDict['retweet_count'][-1] + weights['like'] *outputDict['like_count'][-1]+\n",
        "                                                        weights['reply'] *outputDict['reply_count'][-1] + weights['quote'] *outputDict['quote_count'][-1])/followers)\n",
        "\n",
        "            # referenced tweets: quotes, replies, and retweets\n",
        "            try:\n",
        "                refdTweets = tweet['referenced_tweets']\n",
        "                outputDict['num_referenced_tweets'].append(len(refdTweets))\n",
        "\n",
        "                rtweet = False\n",
        "                reply = False\n",
        "                quote = False\n",
        "                # there may be multiple referenced tweets, apparently. So it could be a reply and contain a quote, I guess\n",
        "                for t in refdTweets:\n",
        "                    typ = t['type']\n",
        "                    if typ == 'retweeted':\n",
        "                        outputDict['is_retweet'].append(True)\n",
        "                        rtweet = True\n",
        "                    elif typ == 'quoted':\n",
        "                        outputDict['contains_quote'].append(True)\n",
        "                        quote = True\n",
        "                    elif typ == 'replied_to':\n",
        "                        outputDict['is_reply'].append(True)\n",
        "                        reply = True\n",
        "                        \n",
        "                if not rtweet:\n",
        "                        outputDict['is_retweet'].append(False)\n",
        "                if not reply:\n",
        "                        outputDict['is_reply'].append(False)\n",
        "                if not quote:\n",
        "                        outputDict['contains_quote'].append(False)\n",
        "            except:\n",
        "                outputDict['num_referenced_tweets'].append(0)\n",
        "                outputDict['is_retweet'].append(False)\n",
        "                outputDict['contains_quote'].append(False)\n",
        "                outputDict['is_reply'].append(False)\n",
        "\n",
        "\n",
        "            # image\n",
        "            try:\n",
        "                outputDict['url_image'].append(tweet['entities']['urls'][0]['images'][0]['url'])  #just grabbing the first image in the first url\n",
        "            except:\n",
        "                outputDict['url_image'].append(\"\")\n",
        "\n",
        "            # hashtags\n",
        "            try:\n",
        "                outputDict['num_hashtags'].append(len(tweet['entities']['hashtags']))\n",
        "                # grabbing just the first hashtag\n",
        "                outputDict['text_first_hashtag'].append(tweet['entities']['hashtags'][0]['tag'])\n",
        "            except:\n",
        "                outputDict['num_hashtags'].append(0) \n",
        "                outputDict['text_first_hashtag'].append(\"\")\n",
        "\n",
        "            # mentions\n",
        "            try: outputDict['num_mentions'].append(len(tweet['entities']['mentions']))\n",
        "            except: outputDict['num_mentions'].append(0)\n",
        "\n",
        "            # cashtags\n",
        "            try: outputDict['num_cashtags'].append(len(tweet['entities']['cashtags']))\n",
        "            except: outputDict['num_cashtags'].append(0)\n",
        "            \n",
        "            # polls\n",
        "            try:\n",
        "                outputDict['num_polls'].append(len(tweet['attachments']['poll_ids']))\n",
        "            except:\n",
        "                outputDict['num_polls'].append(0) \n",
        "                pass\n",
        "        \n",
        "    df = pd.DataFrame(outputDict)\n",
        "\n",
        "\n",
        "    return df, token\n",
        "\n",
        "def get_api_data(usernames, replies = False, numTweets = 10, tweetsPerPage = 10, print_status = False):\n",
        "    import time\n",
        "    import traceback\n",
        "    usersDict =  {'following_count':[], 'tweet_count':[], 'followers_count':[], 'listed_count':[], 'handle':[], 'name':[], 'id':[], \n",
        "    'verified': [], 'protected': [],'created_at': [],'description': [], 'hasPinnedTweet':[], 'urlsInDescription':[], 'hashtagsInDescription':[],\n",
        "    'userWebsitesAdded':[], 'cashtagsInDescription':[],'mentionsInDescription':[]}\n",
        "\n",
        "    idDict = {}\n",
        "\n",
        "    for username in usernames:\n",
        "        # get data related to user account\n",
        "        userData = get_user_data(username)\n",
        "        \n",
        "        # create id - username mapping dictionary for use in next loop\n",
        "        idDict[userData['handle']] = userData['id']\n",
        "        \n",
        "        # build the user data dataframe\n",
        "        for k, v in userData.items():\n",
        "            usersDict[k].append(v)\n",
        "\n",
        "    df_user = pd.DataFrame(usersDict)\n",
        "    \n",
        "    if not replies:\n",
        "        #if we are excluding replies, we want to keep pulling until we have at least 500 images\n",
        "        numImages = 0\n",
        "        tokenDict = {}\n",
        "        stopList = []\n",
        "        nextToken = \"\"\n",
        "        firstIteration = True\n",
        "        loopCount = 1\n",
        "        df_tweets = None\n",
        "        while (numImages < 500):\n",
        "            for username in usernames:\n",
        "                # get data from tweets of the user\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if set(stopList) == set(usernames):\n",
        "                    df_tweets.set_index('id', inplace=True)\n",
        "                    df_user.set_index('handle', inplace=True)\n",
        "                    df_tweets.sort_values('handle', inplace=True)\n",
        "                    return df_tweets, df_user\n",
        "                elif stopList.count(username) > 0:\n",
        "                    continue\n",
        "\n",
        "                # if we left off on a page, then jump to the next page of tweet results\n",
        "                try:\n",
        "                    nextToken = tokenDict[username]\n",
        "                    try:\n",
        "                        df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies, paginationToken=nextToken)\n",
        "                    except Exception:\n",
        "                        traceback.print_exc()\n",
        "                except: \n",
        "                    df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)\n",
        "\n",
        "                tokenDict[username] = token\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if token == None:\n",
        "                    stopList.append(username)\n",
        "\n",
        "                if not firstIteration:\n",
        "                    df_tweets = pd.concat([df_tweets, df_sub])\n",
        "                else:\n",
        "                    df_tweets = df_sub\n",
        "                    firstIteration = False\n",
        "                if print_status: \n",
        "                    num_tweets = len(df_sub)\n",
        "                    print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "            numImages = len(df_tweets[df_tweets.url_image != \"\"])\n",
        "            if print_status: print(f\"{loopCount} iterations through while loop. {numImages} images retrieved.\")\n",
        "            loopCount += 1\n",
        "    else:\n",
        "        df_tweets = None\n",
        "        firstIteration = True\n",
        "        for username in usernames:\n",
        "            # get data from tweets of the user\n",
        "            df_sub = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)[0]\n",
        "\n",
        "            if not firstIteration:\n",
        "                df_tweets = pd.concat([df_tweets, df_sub])\n",
        "            else:\n",
        "                df_tweets = df_sub\n",
        "                firstIteration = False\n",
        "            if print_status: \n",
        "                num_tweets = len(df_sub)\n",
        "                print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "        \n",
        "\n",
        "    df_tweets.set_index('id', inplace=True)\n",
        "    df_user.set_index('handle', inplace=True)\n",
        "    df_tweets.sort_values('handle', inplace=True)\n",
        "\n",
        "    return df_tweets, df_user\n",
        "\n",
        "def dataRetrieval(method = 'csv'):\n",
        "    methods = ['csv', 'api']\n",
        "    if method not in methods:\n",
        "        raise ValueError(\"Invalid method. Expected one of: %s\" % methods)\n",
        "\n",
        "    if method == 'api':\n",
        "        twitter_handles = get_fast_food_handles()\n",
        "        reply_tweetDf, userDf = get_api_data(twitter_handles, replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "        noreply_tweetDf = get_api_data(twitter_handles, replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)[0]\n",
        "\n",
        "        noreply_tweetDf.to_csv('noReplies.csv')\n",
        "        reply_tweetDf.to_csv('replies.csv')\n",
        "        userDf.to_csv('userData.csv')\n",
        "\n",
        "        return userDf, reply_tweetDf, noreply_tweetDf\n",
        "    elif method == 'csv':\n",
        "        userDf = pd.read_csv('userData.csv')\n",
        "        reply_tweetDf = pd.read_csv('replies.csv')\n",
        "        noreply_tweetDf = pd.read_csv('noReplies.csv')\n",
        "\n",
        "        userDf.set_index('handle', inplace= True)\n",
        "        reply_tweetDf.set_index('id', inplace= True)\n",
        "        noreply_tweetDf.set_index('id', inplace= True)\n",
        "\n",
        "\n",
        "        return userDf, reply_tweetDf, noreply_tweetDf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Data retrieved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 626,
      "metadata": {},
      "outputs": [],
      "source": [
        "userDf, reply_tweetDf, noreply_tweetDf = dataRetrieval(method = 'csv') # use method = api to pull from api and overwrite csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 627,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>following_count</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>listed_count</th>\n",
              "      <th>name</th>\n",
              "      <th>...</th>\n",
              "      <th>urlsInDescription</th>\n",
              "      <th>hashtagsInDescription</th>\n",
              "      <th>userWebsitesAdded</th>\n",
              "      <th>cashtagsInDescription</th>\n",
              "      <th>mentionsInDescription</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>handle</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Schlotzskys</th>\n",
              "      <td>18747</td>\n",
              "      <td>64207</td>\n",
              "      <td>19597</td>\n",
              "      <td>254</td>\n",
              "      <td>Schlotzsky's</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AuntieAnnes</th>\n",
              "      <td>32221</td>\n",
              "      <td>88526</td>\n",
              "      <td>65027</td>\n",
              "      <td>724</td>\n",
              "      <td>Auntie Anne's</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             following_count  tweet_count  followers_count  listed_count           name  ...  urlsInDescription  hashtagsInDescription  userWebsitesAdded cashtagsInDescription mentionsInDescription\n",
              "handle                                                                                   ...                                                                                                         \n",
              "Schlotzskys            18747        64207            19597           254   Schlotzsky's  ...                  0                      0                  1                     0                     0\n",
              "AuntieAnnes            32221        88526            65027           724  Auntie Anne's  ...                  0                      0                  1                     0                     0\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "execution_count": 627,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option('display.max_columns', 10)\n",
        "userDf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 628,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handle</th>\n",
              "      <th>followers</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>...</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>text_first_hashtag</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>num_cashtags</th>\n",
              "      <th>num_polls</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1467304737066344454</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>@K0hai_ Thank you for taking the time to share...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469073285749035013</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>Introducing Metaverse Monday! We've been cooki...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        handle  followers                                               text lang  possibly_sensitive  ...  num_hashtags  text_first_hashtag  num_mentions  num_cashtags num_polls\n",
              "id                                                                                                                     ...                                                                        \n",
              "1467304737066344454  Applebees     599611  @K0hai_ Thank you for taking the time to share...   en               False  ...             0                 NaN             1             0         0\n",
              "1469073285749035013  Applebees     599611  Introducing Metaverse Monday! We've been cooki...   en               False  ...             0                 NaN             0             0         0\n",
              "\n",
              "[2 rows x 22 columns]"
            ]
          },
          "execution_count": 628,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reply_tweetDf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 629,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handle</th>\n",
              "      <th>followers</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>...</th>\n",
              "      <th>text_first_hashtag</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>num_cashtags</th>\n",
              "      <th>num_polls</th>\n",
              "      <th>interaction_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1221160812389203969</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>Hurry in before the blue moon is gone. Not tha...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106316070821003265</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599611</td>\n",
              "      <td>cool me neither</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        handle  followers                                               text lang  possibly_sensitive  ...  text_first_hashtag  num_mentions  num_cashtags  num_polls interaction_score\n",
              "id                                                                                                                     ...                                                                             \n",
              "1221160812389203969  Applebees     599611  Hurry in before the blue moon is gone. Not tha...   en               False  ...                 NaN             0             0          0          0.000101\n",
              "1106316070821003265  Applebees     599611                                    cool me neither   en               False  ...                 NaN             0             0          0          0.000194\n",
              "\n",
              "[2 rows x 23 columns]"
            ]
          },
          "execution_count": 629,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### adding features for individual tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 630,
      "metadata": {},
      "outputs": [],
      "source": [
        "def addWordCount(df):\n",
        "\n",
        "    wordCountData = []\n",
        "    for row, index in df['text'].items():\n",
        "        text = df.at[row,'text']\n",
        "        ltext = text.split()\n",
        "        wordCount = len(ltext)\n",
        "        wordCountData.append(wordCount)\n",
        "    \n",
        "    df['tweet_word_count'] = wordCountData\n",
        "\n",
        "    return df\n",
        "\n",
        "reply_tweetDf = addWordCount(reply_tweetDf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### aggregation of features (Except text and image features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 631,
      "metadata": {},
      "outputs": [],
      "source": [
        "def replyAggregationFeatures(df, groupByFeature): \n",
        "\n",
        "    numericCols = [groupByFeature]\n",
        "    categoricalCols = [groupByFeature]\n",
        "    nameMapper = {}\n",
        "    df2 = df.drop(columns=groupByFeature)\n",
        "\n",
        "    # reply ratio\n",
        "    dfReplyRatio = df[['is_reply',groupByFeature]]\n",
        "    dfReplyRatio = dfReplyRatio.groupby(groupByFeature).mean()\n",
        "    nameMapper['is_reply'] = 'replyPercentage'  # what percentage of the recent tweets pulled were replies? \n",
        "\n",
        "    df2 = df2[df2.is_reply == True]\n",
        "    # now pulling from just the replies\n",
        "    for col in df2.columns:\n",
        "        if col == 'is_reply':\n",
        "            continue\n",
        "        if pd.api.types.is_numeric_dtype(df2[col]):\n",
        "            numericCols.append(col)\n",
        "            nameMapper[col] = col + \"_avg_of_reply_tweets\"\n",
        "        else:   \n",
        "            categoricalCols.append(col)\n",
        "            nameMapper[col] = col + \"_mode_of_reply_tweets\"\n",
        "    \n",
        "    # numeric\n",
        "    dfNumeric = df[numericCols]\n",
        "    dfNumeric = dfNumeric.groupby(groupByFeature).mean()\n",
        "    \n",
        "    # categorical\n",
        "    dfCategorical = df[categoricalCols]\n",
        "    dfCategorical = dfCategorical.groupby(groupByFeature).agg(pd.Series.mode)\n",
        "\n",
        "    df = dfNumeric.join(dfCategorical)\n",
        "    df = df.join(dfReplyRatio)\n",
        "    df.rename(columns=nameMapper, inplace=True)\n",
        "\n",
        "    #drop cols I don't think will be of use\n",
        "    df.drop(columns=['followers_avg_of_reply_tweets',\n",
        "       'retweet_count_avg_of_reply_tweets', 'reply_count_avg_of_reply_tweets',\n",
        "       'like_count_avg_of_reply_tweets', 'quote_count_avg_of_reply_tweets',\n",
        "        'text_mode_of_reply_tweets',\n",
        "       'created_at_mode_of_reply_tweets',\n",
        "       'url_image_mode_of_reply_tweets',\n",
        "       'text_first_hashtag_mode_of_reply_tweets'], inplace= True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def noReplyAggregationFeatures(df, groupByFeature): \n",
        "    df.drop(columns=['followers', 'text','retweet_count', 'reply_count', 'like_count', 'quote_count','text_first_hashtag','url_image','is_reply', 'created_at'], inplace= True)\n",
        "    numericCols = [groupByFeature]\n",
        "    categoricalCols = [groupByFeature]\n",
        "    nameMapper = {}\n",
        "    df2 = df.drop(columns=groupByFeature)\n",
        "\n",
        "    for col in df2.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df2[col]):\n",
        "            numericCols.append(col)\n",
        "            nameMapper[col] = col + \"_avg_of_nonreply_tweets\"\n",
        "        else:   \n",
        "            categoricalCols.append(col)\n",
        "            nameMapper[col] = col + \"_mode_of_nonreply_tweets\"\n",
        "    \n",
        "    # numeric\n",
        "    dfNumeric = df[numericCols]\n",
        "    dfNumeric = dfNumeric.groupby(groupByFeature).mean()\n",
        "    \n",
        "    # categorical\n",
        "    dfCategorical = df[categoricalCols]\n",
        "    dfCategorical = dfCategorical.groupby(groupByFeature).agg(pd.Series.mode)\n",
        "\n",
        "    df = dfNumeric.join(dfCategorical)\n",
        "    df.rename(columns=nameMapper, inplace=True)\n",
        "    return df\n",
        "    \n",
        "def generalAggregationFeatures(df, groupByFeature): \n",
        "    # can use this as a starting point for the text and image classification dataframe aggregations, although I don't think there will be any categorical variables\n",
        "    numericCols = [groupByFeature]\n",
        "    categoricalCols = [groupByFeature]\n",
        "    nameMapper = {}\n",
        "    df2 = df.drop(columns=groupByFeature)\n",
        "\n",
        "    for col in df2.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df2[col]):\n",
        "            numericCols.append(col)\n",
        "            nameMapper[col] = col + \"_avg_of_nonreply_tweets\"\n",
        "        else:   \n",
        "            categoricalCols.append(col)\n",
        "            nameMapper[col] = col + \"_mode_of_nonreply_tweets\"\n",
        "    \n",
        "    # numeric\n",
        "    dfNumeric = df[numericCols]\n",
        "    dfNumeric = dfNumeric.groupby(groupByFeature).mean()\n",
        "    \n",
        "    # categorical\n",
        "    dfCategorical = df[categoricalCols]\n",
        "    dfCategorical = dfCategorical.groupby(groupByFeature).agg(pd.Series.mode)\n",
        "\n",
        "    df = dfNumeric.join(dfCategorical)\n",
        "    df.rename(columns=nameMapper, inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 632,
      "metadata": {},
      "outputs": [],
      "source": [
        "noReply_agg = noReplyAggregationFeatures(noreply_tweetDf, 'handle')\n",
        "reply_agg = replyAggregationFeatures(reply_tweetDf, groupByFeature='handle') \n",
        "user_join_ready =  userDf.drop(columns=['tweet_count', 'followers_count', 'listed_count',\n",
        "       'name', 'id', 'description'])\n",
        "\n",
        "df_f = noReply_agg.join(reply_agg)\n",
        "df_f = df_f.join(user_join_ready)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 633,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>possibly_sensitive_avg_of_nonreply_tweets</th>\n",
              "      <th>is_retweet_avg_of_nonreply_tweets</th>\n",
              "      <th>contains_quote_avg_of_nonreply_tweets</th>\n",
              "      <th>num_referenced_tweets_avg_of_nonreply_tweets</th>\n",
              "      <th>num_hashtags_avg_of_nonreply_tweets</th>\n",
              "      <th>...</th>\n",
              "      <th>urlsInDescription</th>\n",
              "      <th>hashtagsInDescription</th>\n",
              "      <th>userWebsitesAdded</th>\n",
              "      <th>cashtagsInDescription</th>\n",
              "      <th>mentionsInDescription</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>handle</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Applebees</th>\n",
              "      <td>0.001252</td>\n",
              "      <td>0.005006</td>\n",
              "      <td>0.027534</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.244055</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arbys</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.303526</td>\n",
              "      <td>0.076826</td>\n",
              "      <td>0.448363</td>\n",
              "      <td>0.306045</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           possibly_sensitive_avg_of_nonreply_tweets  is_retweet_avg_of_nonreply_tweets  contains_quote_avg_of_nonreply_tweets  num_referenced_tweets_avg_of_nonreply_tweets  num_hashtags_avg_of_nonreply_tweets  ...  urlsInDescription  hashtagsInDescription  userWebsitesAdded  cashtagsInDescription mentionsInDescription\n",
              "handle                                                                                                                                                                                                             ...                                                                                                          \n",
              "Applebees                                   0.001252                           0.005006                               0.027534                                      0.058824                             0.244055  ...                  0                      0                  1                      0                     0\n",
              "Arbys                                       0.000000                           0.303526                               0.076826                                      0.448363                             0.306045  ...                  0                      0                  1                      0                     1\n",
              "\n",
              "[2 rows x 35 columns]"
            ]
          },
          "execution_count": 633,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_f.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Export is ready for analysis (but lacks features from image classification and text analytics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 634,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_f.to_csv('analysis_ready_except_text_and_image.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "455-final-project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
