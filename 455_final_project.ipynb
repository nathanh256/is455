{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UekkzUwDavf2"
      },
      "outputs": [],
      "source": [
        "# ### Mount Drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HfSN7hb4aphV"
      },
      "outputs": [],
      "source": [
        "### Imports\n",
        "\n",
        "import os, requests, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Constants\n",
        "\n",
        "WEIGHTS = {\"retweet\" : 3, \"like\" : 0.5 ,\"quote\" : 4 ,\"reply\" : 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2k1VI619aNhd"
      },
      "outputs": [],
      "source": [
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAGXdTwEAAAAAr2%2BC9Wi6GHR8%2Bk%2FiDL2AIHaC1I8%3D86fg9nIXAt2MFp0QP1sXU0q1VFKHAGaD1da68qG4X0glvGSh4D\"\n",
        "\n",
        "def response_health(r):\n",
        "  if r.status_code != 200:\n",
        "    raise Exception(\n",
        "    \"Request returned an error: {} {}\".format(\n",
        "      r.status_code, r.text\n",
        "    )\n",
        "  )\n",
        "    \n",
        "def bearer_oauth(r):\n",
        "  r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "  return r\n",
        "\n",
        "def send_request(url, params=None, print_status=False):\n",
        "  '''Send Request (url) with optional params. Returns json'''\n",
        "  # https://2.python-requests.org/en/master/api/#requests.request\n",
        "  if params == None:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
        "  else:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
        "  if print_status: print(\"Request response status: \", response.status_code)\n",
        "  response_health(response)\n",
        "  return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VvapD2RKjCuA"
      },
      "outputs": [],
      "source": [
        "def get_user_data(name):\n",
        "  # data dictionary scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
        "\n",
        "  userFields = {\"user.fields\":\"created_at, description, entities, id, location, name, pinned_tweet_id, profile_image_url, protected, public_metrics, url, username, verified, withheld\".replace(\" \", \"\")}\n",
        "  user_json = send_request(f\"https://api.twitter.com/2/users/by/username/{name}\",params=userFields)\n",
        "  user_json = user_json[\"data\"]\n",
        "\n",
        "  outputDict = {}\n",
        "  outputDict['following_count'] = user_json['public_metrics']['following_count']\n",
        "  outputDict['tweet_count'] = user_json['public_metrics']['tweet_count']\n",
        "  outputDict['followers_count'] = user_json['public_metrics']['followers_count']\n",
        "  outputDict['listed_count'] = user_json['public_metrics']['listed_count']\n",
        "  outputDict['username'] = user_json['username']\n",
        "  outputDict['name'] = user_json['name']\n",
        "  outputDict['id'] = user_json['id']\n",
        "  outputDict['verified'] = user_json['verified']\n",
        "  outputDict['protected'] = user_json['protected']\n",
        "  outputDict['created_at'] = user_json['created_at']\n",
        "  outputDict['description'] = user_json['description']\n",
        "\n",
        "  try:\n",
        "    test = user_json['pinned_tweet_id']\n",
        "    outputDict['hasPinnedTweet'] = True\n",
        "  except:\n",
        "    outputDict['hasPinnedTweet'] = False\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['urlsInDescription'] = len(user_json['entities']['description']['urls'])\n",
        "  except:\n",
        "    outputDict['urlsInDescription'] = 0\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['hashtagsInDescription'] = len(user_json['entities']['description']['hashtags'])\n",
        "  except:\n",
        "    outputDict['hashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['userWebsitesAdded'] = len(user_json['entities']['url']['urls'])\n",
        "  except:\n",
        "    outputDict['userWebsitesAdded'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['cashtagsInDescription'] = len(user_json['entities']['description']['cashtags'])\n",
        "  except:\n",
        "    outputDict['cashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['mentionsInDescription'] = len(user_json['entities']['description']['mentions'])\n",
        "  except:\n",
        "    outputDict['mentionsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  \n",
        "  return outputDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cBRiEBATn6Kc"
      },
      "outputs": [],
      "source": [
        "def get_tweets_user(id, numTweets = 10, tweetsPerPage = 10, replies = False, weights=WEIGHTS, paginationToken = None):\n",
        "    import math\n",
        "    \n",
        "    # (there are 10 results returned per page by default)\n",
        "    if numTweets < tweetsPerPage:\n",
        "        print(\"numTweets must be greater than or equal to the number of tweets per page.\")\n",
        "        return\n",
        "\n",
        "    # to see data dictionary, click url and scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
        "    expansions = {\"expansions\":\"author_id, attachments.poll_ids, attachments.media_keys, entities.mentions.username, geo.place_id, in_reply_to_user_id, referenced_tweets.id,referenced_tweets.id.author_id\".replace(\" \", \"\")}\n",
        "    tweetFields = {\"tweet.fields\":\"attachments, author_id, context_annotations, conversation_id, created_at, entities, geo, id, in_reply_to_user_id, lang, public_metrics, possibly_sensitive, referenced_tweets, reply_settings, source, text, withheld\".replace(\" \", \"\")}\n",
        "    userFields = {\"user.fields\":\"public_metrics,username\"}\n",
        "    replyFields = {\"exclude\": \"replies\"}\n",
        "\n",
        "    outputDict = {'id':[],'handle':[],'followers':[], 'text':[], 'lang':[],'possibly_sensitive':[],'retweet_count':[],'reply_count':[],'like_count':[],'quote_count':[]\n",
        "        ,'reply_settings':[],'source':[],'created_at':[],'is_retweet':[],'contains_quote':[],'is_reply':[],'num_referenced_tweets':[],\n",
        "        'url_image':[],'num_hashtags':[],'text_first_hashtag':[],'num_mentions':[],'num_cashtags':[],'num_polls':[]}\n",
        "\n",
        "    if not replies:\n",
        "        outputDict['interaction_score'] = []\n",
        "    \n",
        "    if paginationToken != None: \n",
        "        nextToken = paginationToken\n",
        "        \n",
        "    # for each page of results\n",
        "    for i in range(math.ceil(numTweets/tweetsPerPage)): \n",
        "        if i != 0 or paginationToken != None:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":nextToken}}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":nextToken}, **replyFields}\n",
        "        else:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields, **replyFields}\n",
        "\n",
        "\n",
        "        tweet_json = (send_request(f\"https://api.twitter.com/2/users/{id}/tweets\", params=params))\n",
        "        \n",
        "        tweetData = tweet_json['data']\n",
        "\n",
        "        username = tweet_json['includes']['users'][0]['username']\n",
        "        followers = tweet_json['includes']['users'][0]['public_metrics']['followers_count']\n",
        "\n",
        "        for tweet in tweetData:\n",
        "            outputDict['handle'].append(username)\n",
        "            outputDict['followers'].append(followers)\n",
        "            outputDict['id'].append(tweet['id'])\n",
        "            outputDict['text'].append(tweet['text'])\n",
        "            outputDict['lang'].append(tweet['lang'])\n",
        "            outputDict['possibly_sensitive'].append(tweet['possibly_sensitive'])\n",
        "\n",
        "            outputDict['retweet_count'].append(tweet['public_metrics']['retweet_count'])\n",
        "            outputDict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
        "            outputDict['like_count'].append(tweet['public_metrics']['like_count'])\n",
        "            outputDict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
        "            outputDict['reply_settings'].append(tweet['reply_settings'])\n",
        "            outputDict['source'].append(tweet['source'])\n",
        "            outputDict['created_at'].append(tweet['created_at'])\n",
        "\n",
        "            if not replies:\n",
        "                outputDict['interaction_score'].append((weights['retweet'] *outputDict['retweet_count'][-1] + weights['like'] *outputDict['like_count'][-1]+\n",
        "                                                        weights['reply'] *outputDict['reply_count'][-1] + weights['quote'] *outputDict['quote_count'][-1])/followers)\n",
        "\n",
        "            # referenced tweets: quotes, replies, and retweets\n",
        "            try:\n",
        "                refdTweets = tweet['referenced_tweets']\n",
        "                outputDict['num_referenced_tweets'].append(len(refdTweets))\n",
        "\n",
        "                rtweet = False\n",
        "                reply = False\n",
        "                quote = False\n",
        "                # there may be multiple referenced tweets, apparently. So it could be a reply and contain a quote, I guess\n",
        "                for t in refdTweets:\n",
        "                    typ = t['type']\n",
        "                    if typ == 'retweeted':\n",
        "                        outputDict['is_retweet'].append(True)\n",
        "                        rtweet = True\n",
        "                    elif typ == 'quoted':\n",
        "                        outputDict['contains_quote'].append(True)\n",
        "                        quote = True\n",
        "                    elif typ == 'replied_to':\n",
        "                        outputDict['is_reply'].append(True)\n",
        "                        reply = True\n",
        "                        \n",
        "                if not rtweet:\n",
        "                        outputDict['is_retweet'].append(False)\n",
        "                if not reply:\n",
        "                        outputDict['is_reply'].append(False)\n",
        "                if not quote:\n",
        "                        outputDict['contains_quote'].append(False)\n",
        "            except:\n",
        "                outputDict['num_referenced_tweets'].append(0)\n",
        "                outputDict['is_retweet'].append(False)\n",
        "                outputDict['contains_quote'].append(False)\n",
        "                outputDict['is_reply'].append(False)\n",
        "\n",
        "\n",
        "            # image\n",
        "            try:\n",
        "                outputDict['url_image'].append(tweet['entities']['urls'][0]['images'][0]['url'])  #just grabbing the first image in the first url\n",
        "            except:\n",
        "                outputDict['url_image'].append(\"\")\n",
        "\n",
        "            # hashtags\n",
        "            try:\n",
        "                outputDict['num_hashtags'].append(len(tweet['entities']['hashtags']))\n",
        "                # grabbing just the first hashtag\n",
        "                outputDict['text_first_hashtag'].append(tweet['entities']['hashtags'][0]['tag'])\n",
        "            except:\n",
        "                outputDict['num_hashtags'].append(0) \n",
        "                outputDict['text_first_hashtag'].append(\"\")\n",
        "\n",
        "            # mentions\n",
        "            try: outputDict['num_mentions'].append(len(tweet['entities']['mentions']))\n",
        "            except: outputDict['num_mentions'].append(0)\n",
        "\n",
        "            # cashtags\n",
        "            try: outputDict['num_cashtags'].append(len(tweet['entities']['cashtags']))\n",
        "            except: outputDict['num_cashtags'].append(0)\n",
        "            \n",
        "            # polls\n",
        "            try: outputDict['num_polls'].append(len(tweet['attachments']['poll_ids']))\n",
        "            except: outputDict['num_polls'].append(0)\n",
        "\n",
        "\n",
        "        nextToken = tweet_json['meta']['next_token']\n",
        "    \n",
        "    df = pd.DataFrame(outputDict)\n",
        "\n",
        "    tokenDict = {outputDict['handle'][-1] : nextToken}\n",
        "\n",
        "    return df, tokenDict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qwGZb0eTnvrM"
      },
      "outputs": [],
      "source": [
        "def get_api_data(usernames, replies = False, numTweets = 10, tweetsPerPage = 10, print_status = False):\n",
        "    import time\n",
        "    usersDict =  {'following_count':[], 'tweet_count':[], 'followers_count':[], 'listed_count':[], 'username':[], 'name':[], 'id':[], \n",
        "    'verified': [], 'protected': [],'created_at': [],'description': [], 'hasPinnedTweet':[], 'urlsInDescription':[], 'hashtagsInDescription':[],\n",
        "    'userWebsitesAdded':[], 'cashtagsInDescription':[],'mentionsInDescription':[]}\n",
        "\n",
        "    idDict = {}\n",
        "\n",
        "    for username in usernames:\n",
        "        # get data related to user account\n",
        "        userData = get_user_data(username)\n",
        "        \n",
        "        # create id - username mapping dictionary for use in next loop\n",
        "        idDict[userData['username']] = userData['id']\n",
        "        \n",
        "        # build the user data dataframe\n",
        "        for k, v in userData.items():\n",
        "            usersDict[k].append(v)\n",
        "\n",
        "    df_user = pd.DataFrame(usersDict)\n",
        "    \n",
        "    if not replies:\n",
        "        #if we are excluding replies, we want to keep pulling until we have at least 500 images\n",
        "        numImages = 0\n",
        "        tokenDict = {}\n",
        "        firstIteration = True\n",
        "        loopCount = 1\n",
        "        df_tweets = None\n",
        "        while (numImages < 500):\n",
        "            for username in usernames:\n",
        "                # get data from tweets of the user\n",
        "\n",
        "                # if we left off on a page, then jump to the next page of tweet results\n",
        "                try:\n",
        "                    nextToken = tokenDict[username]\n",
        "                    df_sub,tokenD = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies, paginationToken=nextToken)\n",
        "                except: \n",
        "                    df_sub,tokenD = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)\n",
        "\n",
        "                tokenDict[list(tokenD.keys())[0]] = list(tokenD.values())[0]\n",
        "                if not firstIteration:\n",
        "                    df_tweets = pd.concat([df_tweets, df_sub])\n",
        "                else:\n",
        "                    df_tweets = df_sub\n",
        "                    firstIteration = False\n",
        "                if print_status: \n",
        "                    num_tweets = len(df_sub)\n",
        "                    print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "            numImages = len(df_tweets[df_tweets.url_image != \"\"])\n",
        "            if print_status: print(f\"{loopCount} iterations through while loop. {numImages} images retrieved.\")\n",
        "            if loopCount % 3 == 0: # if it is a multiple of 3 \n",
        "                # we have a limit of 900 requests per 15 minute window.\n",
        "                print(\"waiting 13 minutes...\")\n",
        "                time.sleep(60*13) # wait 13 minutes\n",
        "\n",
        "\n",
        "            loopCount += 1\n",
        "            if loopCount == 5: \n",
        "                return df_tweets, df_user\n",
        "    else:\n",
        "        df_tweets = None\n",
        "        firstIteration = True\n",
        "        for username in usernames:\n",
        "            # get data from tweets of the user\n",
        "            df_sub = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)[0]\n",
        "            if not firstIteration:\n",
        "                df_tweets = pd.concat([df_tweets, df_sub])\n",
        "            else:\n",
        "                df_tweets = df_sub\n",
        "                firstIteration = False\n",
        "            if print_status: \n",
        "                num_tweets = len(df_sub)\n",
        "                print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "        \n",
        "    \n",
        "\n",
        "    return df_tweets, df_user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('fast-food-chains - Sheet1.csv')\n",
        "\n",
        "df.drop(df.columns[0], axis=1, inplace=True)\n",
        "df.loc[df.shape[0]] = df.columns\n",
        "df.columns = [\"handle\"]\n",
        "twitter_handles = df[df.columns[0]].tolist()\n",
        "print(len(twitter_handles))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 80 tweets for: Schlotzskys\n",
            "Retrieved 80 tweets for: AuntieAnnes\n",
            "Retrieved 80 tweets for: SaltgrassSteak\n",
            "Retrieved 80 tweets for: redlobster\n",
            "Retrieved 80 tweets for: Hardees\n",
            "Retrieved 80 tweets for: RuthsChris\n",
            "Retrieved 80 tweets for: LongHornSteaks\n",
            "Retrieved 80 tweets for: FiveGuys\n",
            "Retrieved 80 tweets for: Applebees\n",
            "Retrieved 80 tweets for: DelTaco\n",
            "Retrieved 80 tweets for: PFChangs\n",
            "Retrieved 80 tweets for: BonefishGrill\n",
            "Retrieved 80 tweets for: Charleys\n",
            "Retrieved 80 tweets for: EinsteinBros\n",
            "Retrieved 80 tweets for: qdoba\n",
            "Retrieved 80 tweets for: torchystacos\n",
            "Retrieved 80 tweets for: raisingcanes\n",
            "Retrieved 80 tweets for: Cheesecake\n",
            "Retrieved 80 tweets for: WaffleHouse\n",
            "Retrieved 80 tweets for: CheckersRallys\n",
            "Retrieved 80 tweets for: SmoothieKing\n",
            "Retrieved 80 tweets for: CaptainDs\n",
            "Retrieved 80 tweets for: WhiteCastle\n",
            "Retrieved 80 tweets for: papamurphys\n",
            "Retrieved 80 tweets for: caferio\n",
            "Retrieved 80 tweets for: ChuysRestaurant\n",
            "Retrieved 80 tweets for: ChurchsChicken\n",
            "Retrieved 80 tweets for: IHOP\n",
            "Retrieved 80 tweets for: BaskinRobbins\n",
            "Retrieved 80 tweets for: TSmoothieCafe\n",
            "Retrieved 80 tweets for: MODPizza\n",
            "Retrieved 80 tweets for: calpizzakitchen\n",
            "Retrieved 80 tweets for: FreddysUSA\n",
            "Retrieved 80 tweets for: SteaknShake\n",
            "Retrieved 80 tweets for: tacojohns\n",
            "Retrieved 80 tweets for: Dickeys\n",
            "Retrieved 80 tweets for: krispykreme\n",
            "Retrieved 80 tweets for: ElPolloLoco\n",
            "Retrieved 80 tweets for: ColdStone\n",
            "Retrieved 80 tweets for: Whataburger\n",
            "Retrieved 80 tweets for: Hooters\n",
            "Retrieved 80 tweets for: Maggianos\n",
            "Retrieved 80 tweets for: hungryhowies\n",
            "Retrieved 80 tweets for: noodlescompany\n",
            "Retrieved 80 tweets for: Carrabbas\n",
            "Retrieved 80 tweets for: shakeshack\n",
            "Retrieved 80 tweets for: jimmyjohns\n",
            "Retrieved 80 tweets for: portilloshotdog\n",
            "Retrieved 80 tweets for: culvers\n",
            "Retrieved 80 tweets for: redrobinburgers\n",
            "Retrieved 80 tweets for: goldencorral\n",
            "Retrieved 80 tweets for: eatatjacks\n",
            "Retrieved 80 tweets for: McAlistersDeli\n",
            "Retrieved 80 tweets for: rubytuesday\n",
            "Retrieved 80 tweets for: BobEvansFarms\n",
            "Retrieved 80 tweets for: CHWinery\n",
            "Retrieved 80 tweets for: jasonsdeli\n",
            "Retrieved 80 tweets for: longjohnsilvers\n",
            "Retrieved 80 tweets for: TGIFridays\n",
            "Retrieved 80 tweets for: Potbelly\n",
            "Retrieved 80 tweets for: wingstop\n",
            "Retrieved 80 tweets for: JambaJuice\n",
            "Retrieved 80 tweets for: cheddarskitchen\n",
            "Retrieved 80 tweets for: CapitalGrille\n",
            "Retrieved 80 tweets for: EatAtPerkins\n",
            "Retrieved 80 tweets for: MillersAleHouse\n",
            "Retrieved 80 tweets for: JetsPizza\n",
            "Retrieved 79 tweets for: ZoesKitchen\n",
            "Retrieved 80 tweets for: peetscoffee\n",
            "Retrieved 80 tweets for: BlazePizza\n",
            "Retrieved 79 tweets for: bostonmarket\n",
            "Retrieved 80 tweets for: OCharleys\n",
            "Retrieved 80 tweets for: jerseymikes\n",
            "Retrieved 80 tweets for: bjsrestaurants\n",
            "Retrieved 80 tweets for: Bojangles\n",
            "Retrieved 80 tweets for: TimHortons\n",
            "Retrieved 80 tweets for: DennysDiner\n",
            "Retrieved 80 tweets for: Chilis\n",
            "Retrieved 80 tweets for: Outback\n",
            "Retrieved 80 tweets for: Moes_HQ\n",
            "Retrieved 80 tweets for: FirehouseSubs\n",
            "Retrieved 80 tweets for: DutchBros\n",
            "Retrieved 80 tweets for: RoundTablePizza\n",
            "Retrieved 80 tweets for: pollotropical\n",
            "Retrieved 80 tweets for: YardHouse\n",
            "Retrieved 80 tweets for: MellowMushroom\n",
            "Retrieved 80 tweets for: texasroadhouse\n",
            "Retrieved 80 tweets for: olivegarden\n",
            "Retrieved 80 tweets for: CrackerBarrel\n",
            "Retrieved 80 tweets for: PapaJohns\n",
            "Retrieved 80 tweets for: habitburger\n",
            "Retrieved 80 tweets for: Zaxbys\n",
            "Retrieved 80 tweets for: BWWings\n",
            "Retrieved 80 tweets for: MarcosPizza\n",
            "Retrieved 80 tweets for: McDonalds\n",
            "Retrieved 80 tweets for: CarlsJr\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 299 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 300 tweets for: Hardees\n",
            "Retrieved 300 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 299 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 297 tweets for: BonefishGrill\n",
            "Retrieved 296 tweets for: Charleys\n",
            "Retrieved 296 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 300 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 300 tweets for: WaffleHouse\n",
            "Retrieved 298 tweets for: CheckersRallys\n",
            "Retrieved 300 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 299 tweets for: WhiteCastle\n",
            "Retrieved 300 tweets for: papamurphys\n",
            "Retrieved 300 tweets for: caferio\n",
            "Retrieved 300 tweets for: ChuysRestaurant\n",
            "Retrieved 296 tweets for: ChurchsChicken\n",
            "Retrieved 300 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 299 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 300 tweets for: tacojohns\n",
            "Retrieved 300 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 298 tweets for: ElPolloLoco\n",
            "Retrieved 299 tweets for: ColdStone\n",
            "Retrieved 300 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 299 tweets for: Maggianos\n",
            "Retrieved 296 tweets for: hungryhowies\n",
            "Retrieved 300 tweets for: noodlescompany\n",
            "Retrieved 299 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 296 tweets for: redrobinburgers\n",
            "Retrieved 300 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 299 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 299 tweets for: jasonsdeli\n",
            "Retrieved 295 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 299 tweets for: Potbelly\n",
            "Retrieved 300 tweets for: wingstop\n",
            "Retrieved 300 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 297 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 300 tweets for: BlazePizza\n",
            "Retrieved 298 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 300 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 299 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 298 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 299 tweets for: RoundTablePizza\n",
            "Retrieved 299 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 300 tweets for: MellowMushroom\n",
            "Retrieved 295 tweets for: texasroadhouse\n",
            "Retrieved 300 tweets for: olivegarden\n",
            "Retrieved 300 tweets for: CrackerBarrel\n",
            "Retrieved 299 tweets for: PapaJohns\n",
            "Retrieved 300 tweets for: habitburger\n",
            "Retrieved 300 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 299 tweets for: MarcosPizza\n",
            "Retrieved 300 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "1 iterations through while loop. 201 images retrieved.\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 300 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 297 tweets for: Hardees\n",
            "Retrieved 299 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 300 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 296 tweets for: BonefishGrill\n",
            "Retrieved 292 tweets for: Charleys\n",
            "Retrieved 299 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 299 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 298 tweets for: WaffleHouse\n",
            "Retrieved 299 tweets for: CheckersRallys\n",
            "Retrieved 298 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 300 tweets for: WhiteCastle\n",
            "Retrieved 293 tweets for: papamurphys\n",
            "Retrieved 297 tweets for: caferio\n",
            "Retrieved 299 tweets for: ChuysRestaurant\n",
            "Retrieved 297 tweets for: ChurchsChicken\n",
            "Retrieved 298 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 298 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 296 tweets for: tacojohns\n",
            "Retrieved 299 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 300 tweets for: ElPolloLoco\n",
            "Retrieved 297 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 298 tweets for: Maggianos\n",
            "Retrieved 298 tweets for: hungryhowies\n",
            "Retrieved 299 tweets for: noodlescompany\n",
            "Retrieved 292 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 299 tweets for: redrobinburgers\n",
            "Retrieved 289 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 284 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 297 tweets for: jasonsdeli\n",
            "Retrieved 282 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 276 tweets for: Potbelly\n",
            "Retrieved 298 tweets for: wingstop\n",
            "Retrieved 299 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 298 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 299 tweets for: BlazePizza\n",
            "Retrieved 300 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 298 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 300 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 300 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 300 tweets for: RoundTablePizza\n",
            "Retrieved 300 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 297 tweets for: MellowMushroom\n",
            "Retrieved 293 tweets for: texasroadhouse\n",
            "Retrieved 299 tweets for: olivegarden\n",
            "Retrieved 298 tweets for: CrackerBarrel\n",
            "Retrieved 300 tweets for: PapaJohns\n",
            "Retrieved 299 tweets for: habitburger\n",
            "Retrieved 297 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 298 tweets for: MarcosPizza\n",
            "Retrieved 299 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "2 iterations through while loop. 284 images retrieved.\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 299 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 300 tweets for: Hardees\n",
            "Retrieved 300 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 299 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 297 tweets for: BonefishGrill\n",
            "Retrieved 296 tweets for: Charleys\n",
            "Retrieved 296 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 300 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 300 tweets for: WaffleHouse\n",
            "Retrieved 298 tweets for: CheckersRallys\n",
            "Retrieved 300 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 299 tweets for: WhiteCastle\n",
            "Retrieved 300 tweets for: papamurphys\n",
            "Retrieved 300 tweets for: caferio\n",
            "Retrieved 300 tweets for: ChuysRestaurant\n",
            "Retrieved 296 tweets for: ChurchsChicken\n",
            "Retrieved 300 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 299 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 300 tweets for: tacojohns\n",
            "Retrieved 300 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 298 tweets for: ElPolloLoco\n",
            "Retrieved 299 tweets for: ColdStone\n",
            "Retrieved 300 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 299 tweets for: Maggianos\n",
            "Retrieved 296 tweets for: hungryhowies\n",
            "Retrieved 300 tweets for: noodlescompany\n",
            "Retrieved 299 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 296 tweets for: redrobinburgers\n",
            "Retrieved 300 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 299 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 299 tweets for: jasonsdeli\n",
            "Retrieved 295 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 299 tweets for: Potbelly\n",
            "Retrieved 300 tweets for: wingstop\n",
            "Retrieved 300 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 297 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 300 tweets for: BlazePizza\n",
            "Retrieved 298 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 300 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 299 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 298 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 299 tweets for: RoundTablePizza\n",
            "Retrieved 299 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 300 tweets for: MellowMushroom\n",
            "Retrieved 295 tweets for: texasroadhouse\n",
            "Retrieved 300 tweets for: olivegarden\n",
            "Retrieved 300 tweets for: CrackerBarrel\n",
            "Retrieved 299 tweets for: PapaJohns\n",
            "Retrieved 300 tweets for: habitburger\n",
            "Retrieved 300 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 299 tweets for: MarcosPizza\n",
            "Retrieved 300 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "3 iterations through while loop. 494 images retrieved.\n",
            "waiting 13 minutes...\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 300 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 297 tweets for: Hardees\n",
            "Retrieved 299 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 300 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 296 tweets for: BonefishGrill\n",
            "Retrieved 292 tweets for: Charleys\n",
            "Retrieved 299 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 299 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 298 tweets for: WaffleHouse\n",
            "Retrieved 299 tweets for: CheckersRallys\n",
            "Retrieved 298 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 300 tweets for: WhiteCastle\n",
            "Retrieved 293 tweets for: papamurphys\n",
            "Retrieved 297 tweets for: caferio\n",
            "Retrieved 299 tweets for: ChuysRestaurant\n",
            "Retrieved 297 tweets for: ChurchsChicken\n",
            "Retrieved 298 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 298 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 296 tweets for: tacojohns\n",
            "Retrieved 299 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 300 tweets for: ElPolloLoco\n",
            "Retrieved 297 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 298 tweets for: Maggianos\n",
            "Retrieved 298 tweets for: hungryhowies\n",
            "Retrieved 299 tweets for: noodlescompany\n",
            "Retrieved 292 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 299 tweets for: redrobinburgers\n",
            "Retrieved 289 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 284 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 297 tweets for: jasonsdeli\n",
            "Retrieved 282 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 276 tweets for: Potbelly\n",
            "Retrieved 298 tweets for: wingstop\n",
            "Retrieved 299 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 298 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 299 tweets for: BlazePizza\n",
            "Retrieved 300 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 298 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 300 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 300 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 300 tweets for: RoundTablePizza\n",
            "Retrieved 300 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 297 tweets for: MellowMushroom\n",
            "Retrieved 293 tweets for: texasroadhouse\n",
            "Retrieved 299 tweets for: olivegarden\n",
            "Retrieved 298 tweets for: CrackerBarrel\n",
            "Retrieved 300 tweets for: PapaJohns\n",
            "Retrieved 299 tweets for: habitburger\n",
            "Retrieved 297 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 298 tweets for: MarcosPizza\n",
            "Retrieved 299 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "4 iterations through while loop. 568 images retrieved.\n"
          ]
        }
      ],
      "source": [
        "reply_tweetDf, userDf = get_api_data(twitter_handles, replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "noreply_tweetDf, userDf = get_api_data(twitter_handles, replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = noreply_tweetDf\n",
        "df['duplicated'] = df.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Schlotzskys        600\n",
              "LongHornSteaks     600\n",
              "calpizzakitchen    600\n",
              "CapitalGrille      600\n",
              "RuthsChris         599\n",
              "rubytuesday        599\n",
              "TGIFridays         599\n",
              "habitburger        599\n",
              "EatAtPerkins       599\n",
              "CaptainDs          599\n",
              "ElPolloLoco        598\n",
              "SaltgrassSteak     598\n",
              "TSmoothieCafe      598\n",
              "JambaJuice         597\n",
              "Outback            597\n",
              "Maggianos          597\n",
              "IHOP               597\n",
              "ChuysRestaurant    597\n",
              "RoundTablePizza    597\n",
              "qdoba              597\n",
              "Hardees            597\n",
              "McAlistersDeli     597\n",
              "caferio            596\n",
              "SteaknShake        596\n",
              "bjsrestaurants     596\n",
              "jasonsdeli         596\n",
              "CarlsJr            596\n",
              "tacojohns          596\n",
              "MellowMushroom     596\n",
              "OCharleys          595\n",
              "ColdStone          595\n",
              "DelTaco            595\n",
              "MillersAleHouse    595\n",
              "torchystacos       595\n",
              "EinsteinBros       595\n",
              "MarcosPizza        594\n",
              "MODPizza           594\n",
              "pollotropical      594\n",
              "eatatjacks         593\n",
              "noodlescompany     593\n",
              "olivegarden        593\n",
              "BaskinRobbins      593\n",
              "JetsPizza          593\n",
              "ZoesKitchen        593\n",
              "BonefishGrill      593\n",
              "culvers            592\n",
              "jimmyjohns         590\n",
              "Carrabbas          590\n",
              "papamurphys        590\n",
              "ChurchsChicken     589\n",
              "AuntieAnnes        587\n",
              "FreddysUSA         583\n",
              "goldencorral       582\n",
              "Charleys           582\n",
              "BobEvansFarms      582\n",
              "raisingcanes       581\n",
              "CHWinery           580\n",
              "WaffleHouse        577\n",
              "Dickeys            576\n",
              "DennysDiner        575\n",
              "Potbelly           573\n",
              "PFChangs           572\n",
              "longjohnsilvers    572\n",
              "peetscoffee        572\n",
              "YardHouse          500\n",
              "jerseymikes        487\n",
              "Cheesecake         484\n",
              "CrackerBarrel      300\n",
              "FirehouseSubs      299\n",
              "SmoothieKing       298\n",
              "bostonmarket       297\n",
              "shakeshack         297\n",
              "Zaxbys             297\n",
              "cheddarskitchen    297\n",
              "redrobinburgers    296\n",
              "hungryhowies       296\n",
              "krispykreme        295\n",
              "CheckersRallys     295\n",
              "portilloshotdog    295\n",
              "WhiteCastle        292\n",
              "BWWings            292\n",
              "FiveGuys           292\n",
              "DutchBros          292\n",
              "wingstop           286\n",
              "BlazePizza         285\n",
              "Name: handle, dtype: int64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option(\"display.max_rows\", 90)\n",
        "df[df['duplicated'] == True]['handle'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "noreply_tweetDf.to_csv('noReplies.csv')\n",
        "reply_tweetDf.to_csv('replies.csv')\n",
        "userDf.to_csv('userData.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_rows\", 50)\n",
        "# noreply_tweetDf.head(180)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [

        "# dfUser = apiData['userData']\n",
        "# dfUser.to_csv('userData.csv')\n",
        "\n",
        "userDf.to_csv(\"userData\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>handle</th>\n",
              "      <th>followers</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>...</th>\n",
              "      <th>contains_quote</th>\n",
              "      <th>is_reply</th>\n",
              "      <th>num_referenced_tweets</th>\n",
              "      <th>url_image</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>text_first_hashtag</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>num_cashtags</th>\n",
              "      <th>num_polls</th>\n",
              "      <th>interaction_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1470424336033013766</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>okay, it happened. everyone gets a free Big Ma...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>509</td>\n",
              "      <td>343</td>\n",
              "      <td>5331</td>\n",
              "      <td>172</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1470423474846027782</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>if @mariahcarey retweets this everyone gets a ...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>1695</td>\n",
              "      <td>700</td>\n",
              "      <td>10658</td>\n",
              "      <td>221</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1469332042232049665</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>just got Mariah Carey’s rider and i’ve got thr...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>444</td>\n",
              "      <td>242</td>\n",
              "      <td>2848</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1467971503987769347</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>ab_ _efghijkl_nopqrstuvwxyz</td>\n",
              "      <td>cs</td>\n",
              "      <td>False</td>\n",
              "      <td>50337</td>\n",
              "      <td>6972</td>\n",
              "      <td>240364</td>\n",
              "      <td>15336</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.077255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1467882876737884162</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>RT @MariahCarey: Check out my new @McDonalds c...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>865</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>https://pbs.twimg.com/news_img/147041483433651...</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>1339994618952359936</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>nice try, you still get medium fries free in o...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>44</td>\n",
              "      <td>73</td>\n",
              "      <td>958</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>1339994617937342466</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>say free french fry friday three times fast</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>141</td>\n",
              "      <td>368</td>\n",
              "      <td>2895</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>1339670130754793473</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>what’s something that ISN’T a McDonald’s Sprit...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>207</td>\n",
              "      <td>1343</td>\n",
              "      <td>4346</td>\n",
              "      <td>378</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>1338846744780693515</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>we did it. get your free Big Mac on our App\\n\\...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>147</td>\n",
              "      <td>138</td>\n",
              "      <td>2050</td>\n",
              "      <td>39</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1338846628275507201</td>\n",
              "      <td>McDonalds</td>\n",
              "      <td>4394661</td>\n",
              "      <td>If this gets 1 RT, everyone can have a free Bi...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>2790</td>\n",
              "      <td>505</td>\n",
              "      <td>6461</td>\n",
              "      <td>410</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>959 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id     handle  followers  \\\n",
              "0    1470424336033013766  McDonalds    4394661   \n",
              "1    1470423474846027782  McDonalds    4394661   \n",
              "2    1469332042232049665  McDonalds    4394661   \n",
              "3    1467971503987769347  McDonalds    4394661   \n",
              "4    1467882876737884162  McDonalds    4394661   \n",
              "..                   ...        ...        ...   \n",
              "235  1339994618952359936  McDonalds    4394661   \n",
              "236  1339994617937342466  McDonalds    4394661   \n",
              "237  1339670130754793473  McDonalds    4394661   \n",
              "238  1338846744780693515  McDonalds    4394661   \n",
              "239  1338846628275507201  McDonalds    4394661   \n",
              "\n",
              "                                                  text lang  \\\n",
              "0    okay, it happened. everyone gets a free Big Ma...   en   \n",
              "1    if @mariahcarey retweets this everyone gets a ...   en   \n",
              "2    just got Mariah Carey’s rider and i’ve got thr...   en   \n",
              "3                          ab_ _efghijkl_nopqrstuvwxyz   cs   \n",
              "4    RT @MariahCarey: Check out my new @McDonalds c...   en   \n",
              "..                                                 ...  ...   \n",
              "235  nice try, you still get medium fries free in o...   en   \n",
              "236        say free french fry friday three times fast   en   \n",
              "237  what’s something that ISN’T a McDonald’s Sprit...   en   \n",
              "238  we did it. get your free Big Mac on our App\\n\\...   en   \n",
              "239  If this gets 1 RT, everyone can have a free Bi...   en   \n",
              "\n",
              "     possibly_sensitive  retweet_count  reply_count  like_count  quote_count  \\\n",
              "0                 False            509          343        5331          172   \n",
              "1                 False           1695          700       10658          221   \n",
              "2                 False            444          242        2848          109   \n",
              "3                 False          50337         6972      240364        15336   \n",
              "4                 False            865            0           0            0   \n",
              "..                  ...            ...          ...         ...          ...   \n",
              "235               False             44           73         958            4   \n",
              "236               False            141          368        2895           49   \n",
              "237               False            207         1343        4346          378   \n",
              "238               False            147          138        2050           39   \n",
              "239               False           2790          505        6461          410   \n",
              "\n",
              "     ... contains_quote is_reply num_referenced_tweets  \\\n",
              "0    ...          False     True                     1   \n",
              "1    ...          False    False                     0   \n",
              "2    ...          False    False                     0   \n",
              "3    ...          False    False                     0   \n",
              "4    ...          False    False                     1   \n",
              "..   ...            ...      ...                   ...   \n",
              "235  ...          False     True                     1   \n",
              "236  ...          False    False                     0   \n",
              "237  ...          False    False                     0   \n",
              "238  ...          False     True                     1   \n",
              "239  ...          False    False                     0   \n",
              "\n",
              "                                             url_image  num_hashtags  \\\n",
              "0                                                                  0   \n",
              "1                                                                  0   \n",
              "2                                                                  0   \n",
              "3                                                                  0   \n",
              "4    https://pbs.twimg.com/news_img/147041483433651...             0   \n",
              "..                                                 ...           ...   \n",
              "235                                                                0   \n",
              "236                                                                0   \n",
              "237                                                                0   \n",
              "238                                                                0   \n",
              "239                                                                0   \n",
              "\n",
              "     text_first_hashtag  num_mentions num_cashtags  num_polls  \\\n",
              "0                                   0            0          0   \n",
              "1                                   1            0          0   \n",
              "2                                   0            0          0   \n",
              "3                                   0            0          0   \n",
              "4                                   2            0          0   \n",
              "..                  ...           ...          ...        ...   \n",
              "235                                 0            0          0   \n",
              "236                                 0            0          0   \n",
              "237                                 0            0          0   \n",
              "238                                 0            0          0   \n",
              "239                                 0            0          0   \n",
              "\n",
              "    interaction_score  \n",
              "0            0.001189  \n",
              "1            0.002730  \n",
              "2            0.000781  \n",
              "3            0.077255  \n",
              "4            0.000590  \n",
              "..                ...  \n",
              "235          0.000159  \n",
              "236          0.000554  \n",
              "237          0.001285  \n",
              "238          0.000400  \n",
              "239          0.003128  \n",
              "\n",
              "[959 rows x 24 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dfUser = apiData['userData']\n",

        "# for key, value in apiData:\n",
        "#   value.to_csv(f'{key}.csv')\n",
        "\n",
        "reply_tweetDf.to_csv(\"replies.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "455-final-project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
