{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UekkzUwDavf2"
      },
      "outputs": [],
      "source": [
        "# ### Mount Drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HfSN7hb4aphV"
      },
      "outputs": [],
      "source": [
        "### Imports\n",
        "\n",
        "import os, requests, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Constants\n",
        "\n",
        "WEIGHTS = {\"retweet\" : 3, \"like\" : 0.5 ,\"quote\" : 4 ,\"reply\" : 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2k1VI619aNhd"
      },
      "outputs": [],
      "source": [
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAGXdTwEAAAAAr2%2BC9Wi6GHR8%2Bk%2FiDL2AIHaC1I8%3D86fg9nIXAt2MFp0QP1sXU0q1VFKHAGaD1da68qG4X0glvGSh4D\"\n",
        "\n",
        "def response_health(r):\n",
        "  if r.status_code != 200:\n",
        "    raise Exception(\n",
        "    \"Request returned an error: {} {}\".format(\n",
        "      r.status_code, r.text\n",
        "    )\n",
        "  )\n",
        "    \n",
        "def bearer_oauth(r):\n",
        "  r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
        "  return r\n",
        "\n",
        "def send_request(url, params=None, print_status=False):\n",
        "  '''Send Request (url) with optional params. Returns json'''\n",
        "  # https://2.python-requests.org/en/master/api/#requests.request\n",
        "  if params == None:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
        "  else:\n",
        "    response = requests.request(\"GET\", url, auth=bearer_oauth, params=params)\n",
        "  if print_status: print(\"Request response status: \", response.status_code)\n",
        "  response_health(response)\n",
        "  return response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "VvapD2RKjCuA"
      },
      "outputs": [],
      "source": [
        "def get_user_data(name):\n",
        "  # data dictionary scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
        "\n",
        "  userFields = {\"user.fields\":\"created_at, description, entities, id, location, name, pinned_tweet_id, profile_image_url, protected, public_metrics, url, username, verified, withheld\".replace(\" \", \"\")}\n",
        "  user_json = send_request(f\"https://api.twitter.com/2/users/by/username/{name}\",params=userFields)\n",
        "  user_json = user_json[\"data\"]\n",
        "\n",
        "  outputDict = {}\n",
        "  outputDict['following_count'] = user_json['public_metrics']['following_count']\n",
        "  outputDict['tweet_count'] = user_json['public_metrics']['tweet_count']\n",
        "  outputDict['followers_count'] = user_json['public_metrics']['followers_count']\n",
        "  outputDict['listed_count'] = user_json['public_metrics']['listed_count']\n",
        "  outputDict['handle'] = user_json['username']\n",
        "  outputDict['name'] = user_json['name']\n",
        "  outputDict['id'] = user_json['id']\n",
        "  outputDict['verified'] = user_json['verified']\n",
        "  outputDict['protected'] = user_json['protected']\n",
        "  outputDict['created_at'] = user_json['created_at']\n",
        "  outputDict['description'] = user_json['description']\n",
        "\n",
        "  try:\n",
        "    test = user_json['pinned_tweet_id']\n",
        "    outputDict['hasPinnedTweet'] = True\n",
        "  except:\n",
        "    outputDict['hasPinnedTweet'] = False\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['urlsInDescription'] = len(user_json['entities']['description']['urls'])\n",
        "  except:\n",
        "    outputDict['urlsInDescription'] = 0\n",
        "    pass\n",
        "  try:\n",
        "    outputDict['hashtagsInDescription'] = len(user_json['entities']['description']['hashtags'])\n",
        "  except:\n",
        "    outputDict['hashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['userWebsitesAdded'] = len(user_json['entities']['url']['urls'])\n",
        "  except:\n",
        "    outputDict['userWebsitesAdded'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['cashtagsInDescription'] = len(user_json['entities']['description']['cashtags'])\n",
        "  except:\n",
        "    outputDict['cashtagsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  try:\n",
        "    outputDict['mentionsInDescription'] = len(user_json['entities']['description']['mentions'])\n",
        "  except:\n",
        "    outputDict['mentionsInDescription'] = 0\n",
        "    pass\n",
        "\n",
        "  \n",
        "  return outputDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "cBRiEBATn6Kc"
      },
      "outputs": [],
      "source": [
        "def get_tweets_user(id, numTweets = 10, tweetsPerPage = 10, replies = False, weights=WEIGHTS, paginationToken = None):\n",
        "    import math\n",
        "    \n",
        "    # (there are 10 results returned per page by default)\n",
        "    if numTweets < tweetsPerPage:\n",
        "        print(\"numTweets must be greater than or equal to the number of tweets per page.\")\n",
        "        return\n",
        "\n",
        "    # to see data dictionary, click url and scroll down to response fields https://developer.twitter.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
        "    expansions = {\"expansions\":\"author_id, attachments.poll_ids, attachments.media_keys, entities.mentions.username, geo.place_id, in_reply_to_user_id, referenced_tweets.id,referenced_tweets.id.author_id\".replace(\" \", \"\")}\n",
        "    tweetFields = {\"tweet.fields\":\"attachments, author_id, context_annotations, conversation_id, created_at, entities, geo, id, in_reply_to_user_id, lang, public_metrics, possibly_sensitive, referenced_tweets, reply_settings, source, text, withheld\".replace(\" \", \"\")}\n",
        "    userFields = {\"user.fields\":\"public_metrics,username\"}\n",
        "    replyFields = {\"exclude\": \"replies\"}\n",
        "\n",
        "    outputDict = {'id':[],'handle':[],'followers':[], 'text':[], 'lang':[],'possibly_sensitive':[],'retweet_count':[],'reply_count':[],'like_count':[],'quote_count':[]\n",
        "        ,'reply_settings':[],'source':[],'created_at':[],'is_retweet':[],'contains_quote':[],'is_reply':[],'num_referenced_tweets':[],\n",
        "        'url_image':[],'num_hashtags':[],'text_first_hashtag':[],'num_mentions':[],'num_cashtags':[],'num_polls':[]}\n",
        "\n",
        "    if not replies:\n",
        "        outputDict['interaction_score'] = []\n",
        "\n",
        "    token = \"\"\n",
        "    \n",
        "    if paginationToken != None: \n",
        "        token = paginationToken\n",
        "        \n",
        "    # for each page of results\n",
        "    for i in range(math.ceil(numTweets/tweetsPerPage)): \n",
        "        if i != 0 or paginationToken != None:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields,**userFields , **{\"pagination_token\":token}, **replyFields}\n",
        "        else:\n",
        "            if replies:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields}\n",
        "            else:\n",
        "                params = {**{'max_results':tweetsPerPage}, **expansions,**tweetFields, **userFields, **replyFields}\n",
        "\n",
        "\n",
        "        tweet_json = (send_request(f\"https://api.twitter.com/2/users/{id}/tweets\", params=params))\n",
        "\n",
        "        # handle cases where there is no next page of tweets to grab\n",
        "        try:\n",
        "            token = tweet_json['meta']['next_token']\n",
        "        except: \n",
        "            token = None # in this case, there is no page to grab next.\n",
        "            pass\n",
        "        if token == None:\n",
        "            break\n",
        "\n",
        "        username = tweet_json['includes']['users'][0]['username']\n",
        "        followers = tweet_json['includes']['users'][0]['public_metrics']['followers_count']\n",
        "        \n",
        "        tweetData = tweet_json['data']\n",
        "        for tweet in tweetData:\n",
        "            outputDict['handle'].append(username)\n",
        "            outputDict['followers'].append(followers)\n",
        "            outputDict['id'].append(tweet['id'])\n",
        "            outputDict['text'].append(tweet['text'])\n",
        "            outputDict['lang'].append(tweet['lang'])\n",
        "            outputDict['possibly_sensitive'].append(tweet['possibly_sensitive'])\n",
        "\n",
        "            outputDict['retweet_count'].append(tweet['public_metrics']['retweet_count'])\n",
        "            outputDict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
        "            outputDict['like_count'].append(tweet['public_metrics']['like_count'])\n",
        "            outputDict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
        "            outputDict['reply_settings'].append(tweet['reply_settings'])\n",
        "            outputDict['source'].append(tweet['source'])\n",
        "            outputDict['created_at'].append(tweet['created_at'])\n",
        "\n",
        "            if not replies:\n",
        "                outputDict['interaction_score'].append((weights['retweet'] *outputDict['retweet_count'][-1] + weights['like'] *outputDict['like_count'][-1]+\n",
        "                                                        weights['reply'] *outputDict['reply_count'][-1] + weights['quote'] *outputDict['quote_count'][-1])/followers)\n",
        "\n",
        "\n",
        "            # referenced tweets: quotes, replies, and retweets\n",
        "            try:\n",
        "                refdTweets = tweet['referenced_tweets']\n",
        "                outputDict['num_referenced_tweets'].append(len(refdTweets))\n",
        "\n",
        "                rtweet = False\n",
        "                reply = False\n",
        "                quote = False\n",
        "                # there may be multiple referenced tweets, apparently. So it could be a reply and contain a quote, I guess\n",
        "                for t in refdTweets:\n",
        "                    typ = t['type']\n",
        "                    if typ == 'retweeted':\n",
        "                        outputDict['is_retweet'].append(True)\n",
        "                        rtweet = True\n",
        "                    elif typ == 'quoted':\n",
        "                        outputDict['contains_quote'].append(True)\n",
        "                        quote = True\n",
        "                    elif typ == 'replied_to':\n",
        "                        outputDict['is_reply'].append(True)\n",
        "                        reply = True\n",
        "                        \n",
        "                if not rtweet:\n",
        "                        outputDict['is_retweet'].append(False)\n",
        "                if not reply:\n",
        "                        outputDict['is_reply'].append(False)\n",
        "                if not quote:\n",
        "                        outputDict['contains_quote'].append(False)\n",
        "\n",
        "            except:\n",
        "                outputDict['num_referenced_tweets'].append(0)\n",
        "                outputDict['is_retweet'].append(False)\n",
        "                outputDict['contains_quote'].append(False)\n",
        "                outputDict['is_reply'].append(False)\n",
        "                pass\n",
        "\n",
        "\n",
        "            # image\n",
        "            try:\n",
        "                outputDict['url_image'].append(tweet['entities']['urls'][0]['images'][0]['url'])  #just grabbing the first image in the first url\n",
        "            except:\n",
        "                outputDict['url_image'].append(\"\")  \n",
        "                pass\n",
        "\n",
        "            # hashtags\n",
        "            try:\n",
        "                outputDict['num_hashtags'].append(len(tweet['entities']['hashtags']))\n",
        "                # grabbing just the first hashtag\n",
        "                outputDict['text_first_hashtag'].append(tweet['entities']['hashtags'][0]['tag'])\n",
        "            except:\n",
        "                outputDict['num_hashtags'].append(0) \n",
        "                outputDict['text_first_hashtag'].append(\"\")   \n",
        "                pass\n",
        "\n",
        "            # mentions\n",
        "            try:\n",
        "                outputDict['num_mentions'].append(len(tweet['entities']['mentions']))\n",
        "            except:\n",
        "                outputDict['num_mentions'].append(0) \n",
        "                pass\n",
        "\n",
        "            # cashtags\n",
        "            try:\n",
        "                outputDict['num_cashtags'].append(len(tweet['entities']['cashtags']))\n",
        "            except:\n",
        "                outputDict['num_cashtags'].append(0) \n",
        "                pass\n",
        "            \n",
        "            # polls\n",
        "            try:\n",
        "                outputDict['num_polls'].append(len(tweet['attachments']['poll_ids']))\n",
        "            except:\n",
        "                outputDict['num_polls'].append(0) \n",
        "                pass\n",
        "        \n",
        "    df = pd.DataFrame(outputDict)\n",
        "\n",
        "\n",
        "    return df, token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "qwGZb0eTnvrM"
      },
      "outputs": [],
      "source": [
        "def get_api_data(usernames, replies = False, numTweets = 10, tweetsPerPage = 10, print_status = False):\n",
        "    import time\n",
        "    import traceback\n",
        "    usersDict =  {'following_count':[], 'tweet_count':[], 'followers_count':[], 'listed_count':[], 'handle':[], 'name':[], 'id':[], \n",
        "    'verified': [], 'protected': [],'created_at': [],'description': [], 'hasPinnedTweet':[], 'urlsInDescription':[], 'hashtagsInDescription':[],\n",
        "    'userWebsitesAdded':[], 'cashtagsInDescription':[],'mentionsInDescription':[]}\n",
        "\n",
        "    idDict = {}\n",
        "\n",
        "    for username in usernames:\n",
        "        # get data related to user account\n",
        "        userData = get_user_data(username)\n",
        "        \n",
        "        # create id - username mapping dictionary for use in next loop\n",
        "        idDict[userData['handle']] = userData['id']\n",
        "        \n",
        "        # build the user data dataframe\n",
        "        for k, v in userData.items():\n",
        "            usersDict[k].append(v)\n",
        "\n",
        "    df_user = pd.DataFrame(usersDict)\n",
        "    \n",
        "    if not replies:\n",
        "        #if we are excluding replies, we want to keep pulling until we have at least 500 images\n",
        "        numImages = 0\n",
        "        tokenDict = {}\n",
        "        stopList = []\n",
        "        nextToken = \"\"\n",
        "        firstIteration = True\n",
        "        loopCount = 1\n",
        "        df_tweets = None\n",
        "        while (numImages < 500):\n",
        "            for username in usernames:\n",
        "                # get data from tweets of the user\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if set(stopList) == set(usernames):\n",
        "                    df_tweets.set_index('id', inplace=True)\n",
        "                    df_user.set_index('handle', inplace=True)\n",
        "                    df_tweets.sort_values('handle', inplace=True)\n",
        "                    return df_tweets, df_user\n",
        "                elif stopList.count(username) > 0:\n",
        "                    continue\n",
        "\n",
        "                # if we left off on a page, then jump to the next page of tweet results\n",
        "                try:\n",
        "                    nextToken = tokenDict[username]\n",
        "                    try:\n",
        "                        df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies, paginationToken=nextToken)\n",
        "                    except Exception:\n",
        "                        traceback.print_exc()\n",
        "                except: \n",
        "                    df_sub,token = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)\n",
        "\n",
        "                tokenDict[username] = token\n",
        "\n",
        "                # handle cases where there are no more tweets to pull \n",
        "                if token == None:\n",
        "                    stopList.append(username)\n",
        "\n",
        "                if not firstIteration:\n",
        "                    df_tweets = pd.concat([df_tweets, df_sub])\n",
        "                else:\n",
        "                    df_tweets = df_sub\n",
        "                    firstIteration = False\n",
        "                if print_status: \n",
        "                    num_tweets = len(df_sub)\n",
        "                    print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "            numImages = len(df_tweets[df_tweets.url_image != \"\"])\n",
        "            if print_status: print(f\"{loopCount} iterations through while loop. {numImages} images retrieved.\")\n",
        "            if loopCount % 3 == 0: # if it is a multiple of 3 \n",
        "                # we have a limit of 900 requests per 15 minute window.\n",
        "                print(\"waiting 5 minutes...\")\n",
        "                time.sleep(60*5) # wait 5 minutes\n",
        "            loopCount += 1\n",
        "    else:\n",
        "        df_tweets = None\n",
        "        firstIteration = True\n",
        "        for username in usernames:\n",
        "            # get data from tweets of the user\n",
        "            df_sub = get_tweets_user(idDict[username], numTweets=numTweets, tweetsPerPage=tweetsPerPage, replies=replies)[0]\n",
        "\n",
        "            if not firstIteration:\n",
        "                df_tweets = pd.concat([df_tweets, df_sub])\n",
        "            else:\n",
        "                df_tweets = df_sub\n",
        "                firstIteration = False\n",
        "            if print_status: \n",
        "                num_tweets = len(df_sub)\n",
        "                print(f\"Retrieved {num_tweets} tweets for: {username}\")\n",
        "        \n",
        "\n",
        "    df_tweets.set_index('id', inplace=True)\n",
        "    df_user.set_index('handle', inplace=True)\n",
        "    df_tweets.sort_values('handle', inplace=True)\n",
        "\n",
        "    return df_tweets, df_user\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "96\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Schlotzskys',\n",
              " 'AuntieAnnes',\n",
              " 'SaltgrassSteak',\n",
              " 'redlobster',\n",
              " 'Hardees',\n",
              " 'RuthsChris',\n",
              " 'LongHornSteaks',\n",
              " 'FiveGuys',\n",
              " 'Applebees',\n",
              " 'DelTaco',\n",
              " 'PFChangs',\n",
              " 'BonefishGrill',\n",
              " 'Charleys',\n",
              " 'EinsteinBros',\n",
              " 'qdoba',\n",
              " 'torchystacos',\n",
              " 'raisingcanes',\n",
              " 'Cheesecake',\n",
              " 'WaffleHouse',\n",
              " 'CheckersRallys',\n",
              " 'SmoothieKing',\n",
              " 'CaptainDs',\n",
              " 'WhiteCastle',\n",
              " 'papamurphys',\n",
              " 'caferio',\n",
              " 'ChuysRestaurant',\n",
              " 'ChurchsChicken',\n",
              " 'IHOP',\n",
              " 'BaskinRobbins',\n",
              " 'TSmoothieCafe',\n",
              " 'MODPizza',\n",
              " 'calpizzakitchen',\n",
              " 'FreddysUSA',\n",
              " 'SteaknShake',\n",
              " 'tacojohns',\n",
              " 'Dickeys',\n",
              " 'krispykreme',\n",
              " 'ElPolloLoco',\n",
              " 'ColdStone',\n",
              " 'Whataburger',\n",
              " 'Hooters',\n",
              " 'Maggianos',\n",
              " 'hungryhowies',\n",
              " 'noodlescompany',\n",
              " 'Carrabbas',\n",
              " 'shakeshack',\n",
              " 'jimmyjohns',\n",
              " 'portilloshotdog',\n",
              " 'culvers',\n",
              " 'redrobinburgers',\n",
              " 'goldencorral',\n",
              " 'eatatjacks',\n",
              " 'McAlistersDeli',\n",
              " 'rubytuesday',\n",
              " 'BobEvansFarms',\n",
              " 'CHWinery',\n",
              " 'jasonsdeli',\n",
              " 'longjohnsilvers',\n",
              " 'TGIFridays',\n",
              " 'Potbelly',\n",
              " 'wingstop',\n",
              " 'JambaJuice',\n",
              " 'cheddarskitchen',\n",
              " 'CapitalGrille',\n",
              " 'EatAtPerkins',\n",
              " 'MillersAleHouse',\n",
              " 'JetsPizza',\n",
              " 'ZoesKitchen',\n",
              " 'peetscoffee',\n",
              " 'BlazePizza',\n",
              " 'bostonmarket',\n",
              " 'OCharleys',\n",
              " 'jerseymikes',\n",
              " 'bjsrestaurants',\n",
              " 'Bojangles',\n",
              " 'TimHortons',\n",
              " 'DennysDiner',\n",
              " 'Chilis',\n",
              " 'Outback',\n",
              " 'Moes_HQ',\n",
              " 'FirehouseSubs',\n",
              " 'DutchBros',\n",
              " 'RoundTablePizza',\n",
              " 'pollotropical',\n",
              " 'YardHouse',\n",
              " 'MellowMushroom',\n",
              " 'texasroadhouse',\n",
              " 'olivegarden',\n",
              " 'CrackerBarrel',\n",
              " 'PapaJohns',\n",
              " 'habitburger',\n",
              " 'Zaxbys',\n",
              " 'BWWings',\n",
              " 'MarcosPizza',\n",
              " 'McDonalds',\n",
              " 'CarlsJr']"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('fast-food-chains - Sheet1.csv')\n",
        "\n",
        "df.drop(df.columns[0], axis=1, inplace=True)\n",
        "df.loc[df.shape[0]] = df.columns\n",
        "df.columns = [\"handle\"]\n",
        "twitter_handles = df[df.columns[0]].tolist()\n",
        "print(len(twitter_handles))\n",
        "twitter_handles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 80 tweets for: Schlotzskys\n",
            "Retrieved 80 tweets for: AuntieAnnes\n",
            "Retrieved 80 tweets for: SaltgrassSteak\n",
            "Retrieved 80 tweets for: redlobster\n",
            "Retrieved 80 tweets for: Hardees\n",
            "Retrieved 80 tweets for: RuthsChris\n",
            "Retrieved 80 tweets for: LongHornSteaks\n",
            "Retrieved 80 tweets for: FiveGuys\n",
            "Retrieved 80 tweets for: Applebees\n",
            "Retrieved 80 tweets for: DelTaco\n",
            "Retrieved 80 tweets for: PFChangs\n",
            "Retrieved 80 tweets for: BonefishGrill\n",
            "Retrieved 80 tweets for: Charleys\n",
            "Retrieved 80 tweets for: EinsteinBros\n",
            "Retrieved 80 tweets for: qdoba\n",
            "Retrieved 80 tweets for: torchystacos\n",
            "Retrieved 80 tweets for: raisingcanes\n",
            "Retrieved 80 tweets for: Cheesecake\n",
            "Retrieved 80 tweets for: WaffleHouse\n",
            "Retrieved 80 tweets for: CheckersRallys\n",
            "Retrieved 80 tweets for: SmoothieKing\n",
            "Retrieved 80 tweets for: CaptainDs\n",
            "Retrieved 80 tweets for: WhiteCastle\n",
            "Retrieved 80 tweets for: papamurphys\n",
            "Retrieved 80 tweets for: caferio\n",
            "Retrieved 80 tweets for: ChuysRestaurant\n",
            "Retrieved 80 tweets for: ChurchsChicken\n",
            "Retrieved 80 tweets for: IHOP\n",
            "Retrieved 80 tweets for: BaskinRobbins\n",
            "Retrieved 80 tweets for: TSmoothieCafe\n",
            "Retrieved 80 tweets for: MODPizza\n",
            "Retrieved 80 tweets for: calpizzakitchen\n",
            "Retrieved 80 tweets for: FreddysUSA\n",
            "Retrieved 80 tweets for: SteaknShake\n",
            "Retrieved 80 tweets for: tacojohns\n",
            "Retrieved 80 tweets for: Dickeys\n",
            "Retrieved 80 tweets for: krispykreme\n",
            "Retrieved 80 tweets for: ElPolloLoco\n",
            "Retrieved 80 tweets for: ColdStone\n",
            "Retrieved 80 tweets for: Whataburger\n",
            "Retrieved 80 tweets for: Hooters\n",
            "Retrieved 80 tweets for: Maggianos\n",
            "Retrieved 80 tweets for: hungryhowies\n",
            "Retrieved 80 tweets for: noodlescompany\n",
            "Retrieved 80 tweets for: Carrabbas\n",
            "Retrieved 80 tweets for: shakeshack\n",
            "Retrieved 80 tweets for: jimmyjohns\n",
            "Retrieved 80 tweets for: portilloshotdog\n",
            "Retrieved 80 tweets for: culvers\n",
            "Retrieved 80 tweets for: redrobinburgers\n",
            "Retrieved 80 tweets for: goldencorral\n",
            "Retrieved 80 tweets for: eatatjacks\n",
            "Retrieved 80 tweets for: McAlistersDeli\n",
            "Retrieved 80 tweets for: rubytuesday\n",
            "Retrieved 80 tweets for: BobEvansFarms\n",
            "Retrieved 80 tweets for: CHWinery\n",
            "Retrieved 80 tweets for: jasonsdeli\n",
            "Retrieved 80 tweets for: longjohnsilvers\n",
            "Retrieved 80 tweets for: TGIFridays\n",
            "Retrieved 80 tweets for: Potbelly\n",
            "Retrieved 80 tweets for: wingstop\n",
            "Retrieved 80 tweets for: JambaJuice\n",
            "Retrieved 80 tweets for: cheddarskitchen\n",
            "Retrieved 80 tweets for: CapitalGrille\n",
            "Retrieved 80 tweets for: EatAtPerkins\n",
            "Retrieved 80 tweets for: MillersAleHouse\n",
            "Retrieved 80 tweets for: JetsPizza\n",
            "Retrieved 80 tweets for: ZoesKitchen\n",
            "Retrieved 80 tweets for: peetscoffee\n",
            "Retrieved 80 tweets for: BlazePizza\n",
            "Retrieved 79 tweets for: bostonmarket\n",
            "Retrieved 80 tweets for: OCharleys\n",
            "Retrieved 80 tweets for: jerseymikes\n",
            "Retrieved 80 tweets for: bjsrestaurants\n",
            "Retrieved 80 tweets for: Bojangles\n",
            "Retrieved 80 tweets for: TimHortons\n",
            "Retrieved 80 tweets for: DennysDiner\n",
            "Retrieved 80 tweets for: Chilis\n",
            "Retrieved 80 tweets for: Outback\n",
            "Retrieved 80 tweets for: Moes_HQ\n",
            "Retrieved 80 tweets for: FirehouseSubs\n",
            "Retrieved 80 tweets for: DutchBros\n",
            "Retrieved 80 tweets for: RoundTablePizza\n",
            "Retrieved 80 tweets for: pollotropical\n",
            "Retrieved 80 tweets for: YardHouse\n",
            "Retrieved 80 tweets for: MellowMushroom\n",
            "Retrieved 80 tweets for: texasroadhouse\n",
            "Retrieved 80 tweets for: olivegarden\n",
            "Retrieved 80 tweets for: CrackerBarrel\n",
            "Retrieved 80 tweets for: PapaJohns\n",
            "Retrieved 80 tweets for: habitburger\n",
            "Retrieved 80 tweets for: Zaxbys\n",
            "Retrieved 80 tweets for: BWWings\n",
            "Retrieved 80 tweets for: MarcosPizza\n",
            "Retrieved 80 tweets for: McDonalds\n",
            "Retrieved 80 tweets for: CarlsJr\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 299 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 300 tweets for: Hardees\n",
            "Retrieved 300 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 299 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 297 tweets for: BonefishGrill\n",
            "Retrieved 296 tweets for: Charleys\n",
            "Retrieved 296 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 300 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 300 tweets for: WaffleHouse\n",
            "Retrieved 298 tweets for: CheckersRallys\n",
            "Retrieved 300 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 299 tweets for: WhiteCastle\n",
            "Retrieved 300 tweets for: papamurphys\n",
            "Retrieved 300 tweets for: caferio\n",
            "Retrieved 300 tweets for: ChuysRestaurant\n",
            "Retrieved 296 tweets for: ChurchsChicken\n",
            "Retrieved 300 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 300 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 300 tweets for: tacojohns\n",
            "Retrieved 300 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 298 tweets for: ElPolloLoco\n",
            "Retrieved 299 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 299 tweets for: Maggianos\n",
            "Retrieved 296 tweets for: hungryhowies\n",
            "Retrieved 300 tweets for: noodlescompany\n",
            "Retrieved 299 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 296 tweets for: redrobinburgers\n",
            "Retrieved 300 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 299 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 299 tweets for: jasonsdeli\n",
            "Retrieved 295 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 299 tweets for: Potbelly\n",
            "Retrieved 300 tweets for: wingstop\n",
            "Retrieved 300 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 297 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 298 tweets for: ZoesKitchen\n",
            "Retrieved 298 tweets for: peetscoffee\n",
            "Retrieved 300 tweets for: BlazePizza\n",
            "Retrieved 298 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 300 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 299 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 298 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 299 tweets for: RoundTablePizza\n",
            "Retrieved 299 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 300 tweets for: MellowMushroom\n",
            "Retrieved 295 tweets for: texasroadhouse\n",
            "Retrieved 300 tweets for: olivegarden\n",
            "Retrieved 300 tweets for: CrackerBarrel\n",
            "Retrieved 299 tweets for: PapaJohns\n",
            "Retrieved 300 tweets for: habitburger\n",
            "Retrieved 300 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 299 tweets for: MarcosPizza\n",
            "Retrieved 300 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "1 iterations through while loop. 245 images retrieved.\n",
            "Retrieved 300 tweets for: Schlotzskys\n",
            "Retrieved 300 tweets for: AuntieAnnes\n",
            "Retrieved 300 tweets for: SaltgrassSteak\n",
            "Retrieved 300 tweets for: redlobster\n",
            "Retrieved 297 tweets for: Hardees\n",
            "Retrieved 299 tweets for: RuthsChris\n",
            "Retrieved 300 tweets for: LongHornSteaks\n",
            "Retrieved 300 tweets for: FiveGuys\n",
            "Retrieved 300 tweets for: Applebees\n",
            "Retrieved 299 tweets for: DelTaco\n",
            "Retrieved 300 tweets for: PFChangs\n",
            "Retrieved 296 tweets for: BonefishGrill\n",
            "Retrieved 292 tweets for: Charleys\n",
            "Retrieved 299 tweets for: EinsteinBros\n",
            "Retrieved 300 tweets for: qdoba\n",
            "Retrieved 299 tweets for: torchystacos\n",
            "Retrieved 300 tweets for: raisingcanes\n",
            "Retrieved 300 tweets for: Cheesecake\n",
            "Retrieved 298 tweets for: WaffleHouse\n",
            "Retrieved 299 tweets for: CheckersRallys\n",
            "Retrieved 298 tweets for: SmoothieKing\n",
            "Retrieved 300 tweets for: CaptainDs\n",
            "Retrieved 300 tweets for: WhiteCastle\n",
            "Retrieved 293 tweets for: papamurphys\n",
            "Retrieved 297 tweets for: caferio\n",
            "Retrieved 299 tweets for: ChuysRestaurant\n",
            "Retrieved 297 tweets for: ChurchsChicken\n",
            "Retrieved 298 tweets for: IHOP\n",
            "Retrieved 300 tweets for: BaskinRobbins\n",
            "Retrieved 300 tweets for: TSmoothieCafe\n",
            "Retrieved 298 tweets for: MODPizza\n",
            "Retrieved 300 tweets for: calpizzakitchen\n",
            "Retrieved 299 tweets for: FreddysUSA\n",
            "Retrieved 300 tweets for: SteaknShake\n",
            "Retrieved 296 tweets for: tacojohns\n",
            "Retrieved 299 tweets for: Dickeys\n",
            "Retrieved 300 tweets for: krispykreme\n",
            "Retrieved 300 tweets for: ElPolloLoco\n",
            "Retrieved 297 tweets for: ColdStone\n",
            "Retrieved 299 tweets for: Whataburger\n",
            "Retrieved 300 tweets for: Hooters\n",
            "Retrieved 298 tweets for: Maggianos\n",
            "Retrieved 298 tweets for: hungryhowies\n",
            "Retrieved 299 tweets for: noodlescompany\n",
            "Retrieved 292 tweets for: Carrabbas\n",
            "Retrieved 300 tweets for: shakeshack\n",
            "Retrieved 297 tweets for: jimmyjohns\n",
            "Retrieved 300 tweets for: portilloshotdog\n",
            "Retrieved 300 tweets for: culvers\n",
            "Retrieved 299 tweets for: redrobinburgers\n",
            "Retrieved 289 tweets for: goldencorral\n",
            "Retrieved 300 tweets for: eatatjacks\n",
            "Retrieved 300 tweets for: McAlistersDeli\n",
            "Retrieved 300 tweets for: rubytuesday\n",
            "Retrieved 284 tweets for: BobEvansFarms\n",
            "Retrieved 300 tweets for: CHWinery\n",
            "Retrieved 297 tweets for: jasonsdeli\n",
            "Retrieved 282 tweets for: longjohnsilvers\n",
            "Retrieved 300 tweets for: TGIFridays\n",
            "Retrieved 277 tweets for: Potbelly\n",
            "Retrieved 298 tweets for: wingstop\n",
            "Retrieved 299 tweets for: JambaJuice\n",
            "Retrieved 300 tweets for: cheddarskitchen\n",
            "Retrieved 300 tweets for: CapitalGrille\n",
            "Retrieved 300 tweets for: EatAtPerkins\n",
            "Retrieved 298 tweets for: MillersAleHouse\n",
            "Retrieved 300 tweets for: JetsPizza\n",
            "Retrieved 297 tweets for: ZoesKitchen\n",
            "Retrieved 299 tweets for: peetscoffee\n",
            "Retrieved 299 tweets for: BlazePizza\n",
            "Retrieved 300 tweets for: bostonmarket\n",
            "Retrieved 300 tweets for: OCharleys\n",
            "Retrieved 298 tweets for: jerseymikes\n",
            "Retrieved 300 tweets for: bjsrestaurants\n",
            "Retrieved 300 tweets for: Bojangles\n",
            "Retrieved 300 tweets for: TimHortons\n",
            "Retrieved 300 tweets for: DennysDiner\n",
            "Retrieved 300 tweets for: Chilis\n",
            "Retrieved 300 tweets for: Outback\n",
            "Retrieved 300 tweets for: Moes_HQ\n",
            "Retrieved 300 tweets for: FirehouseSubs\n",
            "Retrieved 298 tweets for: DutchBros\n",
            "Retrieved 300 tweets for: RoundTablePizza\n",
            "Retrieved 300 tweets for: pollotropical\n",
            "Retrieved 300 tweets for: YardHouse\n",
            "Retrieved 297 tweets for: MellowMushroom\n",
            "Retrieved 293 tweets for: texasroadhouse\n",
            "Retrieved 299 tweets for: olivegarden\n",
            "Retrieved 298 tweets for: CrackerBarrel\n",
            "Retrieved 300 tweets for: PapaJohns\n",
            "Retrieved 299 tweets for: habitburger\n",
            "Retrieved 297 tweets for: Zaxbys\n",
            "Retrieved 300 tweets for: BWWings\n",
            "Retrieved 298 tweets for: MarcosPizza\n",
            "Retrieved 299 tweets for: McDonalds\n",
            "Retrieved 300 tweets for: CarlsJr\n",
            "2 iterations through while loop. 336 images retrieved.\n",
            "Retrieved 200 tweets for: Schlotzskys\n",
            "Retrieved 191 tweets for: AuntieAnnes\n",
            "Retrieved 200 tweets for: SaltgrassSteak\n",
            "Retrieved 200 tweets for: redlobster\n",
            "Retrieved 200 tweets for: Hardees\n",
            "Retrieved 191 tweets for: RuthsChris\n",
            "Retrieved 200 tweets for: LongHornSteaks\n",
            "Retrieved 199 tweets for: FiveGuys\n",
            "Retrieved 200 tweets for: Applebees\n",
            "Retrieved 200 tweets for: DelTaco\n",
            "Retrieved 200 tweets for: PFChangs\n",
            "Retrieved 195 tweets for: BonefishGrill\n",
            "Retrieved 200 tweets for: Charleys\n",
            "Retrieved 186 tweets for: EinsteinBros\n",
            "Retrieved 200 tweets for: qdoba\n",
            "Retrieved 198 tweets for: torchystacos\n",
            "Retrieved 200 tweets for: raisingcanes\n",
            "Retrieved 200 tweets for: Cheesecake\n",
            "Retrieved 196 tweets for: WaffleHouse\n",
            "Retrieved 198 tweets for: CheckersRallys\n",
            "Retrieved 200 tweets for: SmoothieKing\n",
            "Retrieved 199 tweets for: CaptainDs\n",
            "Retrieved 200 tweets for: WhiteCastle\n",
            "Retrieved 198 tweets for: papamurphys\n",
            "Retrieved 196 tweets for: caferio\n",
            "Retrieved 197 tweets for: ChuysRestaurant\n",
            "Retrieved 200 tweets for: ChurchsChicken\n",
            "Retrieved 200 tweets for: IHOP\n",
            "Retrieved 200 tweets for: BaskinRobbins\n",
            "Retrieved 185 tweets for: TSmoothieCafe\n",
            "Retrieved 200 tweets for: MODPizza\n",
            "Retrieved 199 tweets for: calpizzakitchen\n",
            "Retrieved 196 tweets for: FreddysUSA\n",
            "Retrieved 200 tweets for: SteaknShake\n",
            "Retrieved 197 tweets for: tacojohns\n",
            "Retrieved 200 tweets for: Dickeys\n",
            "Retrieved 200 tweets for: krispykreme\n",
            "Retrieved 200 tweets for: ElPolloLoco\n",
            "Retrieved 199 tweets for: ColdStone\n",
            "Retrieved 199 tweets for: Whataburger\n",
            "Retrieved 200 tweets for: Hooters\n",
            "Retrieved 200 tweets for: Maggianos\n",
            "Retrieved 200 tweets for: hungryhowies\n",
            "Retrieved 199 tweets for: noodlescompany\n",
            "Retrieved 197 tweets for: Carrabbas\n",
            "Retrieved 200 tweets for: shakeshack\n",
            "Retrieved 190 tweets for: jimmyjohns\n",
            "Retrieved 197 tweets for: portilloshotdog\n",
            "Retrieved 200 tweets for: culvers\n",
            "Retrieved 200 tweets for: redrobinburgers\n",
            "Retrieved 189 tweets for: goldencorral\n",
            "Retrieved 198 tweets for: eatatjacks\n",
            "Retrieved 200 tweets for: McAlistersDeli\n",
            "Retrieved 200 tweets for: rubytuesday\n",
            "Retrieved 83 tweets for: BobEvansFarms\n",
            "Retrieved 198 tweets for: CHWinery\n",
            "Retrieved 200 tweets for: jasonsdeli\n",
            "Retrieved 191 tweets for: longjohnsilvers\n",
            "Retrieved 200 tweets for: TGIFridays\n",
            "Retrieved 185 tweets for: Potbelly\n",
            "Retrieved 200 tweets for: wingstop\n",
            "Retrieved 198 tweets for: JambaJuice\n",
            "Retrieved 198 tweets for: cheddarskitchen\n",
            "Retrieved 199 tweets for: CapitalGrille\n",
            "Retrieved 197 tweets for: EatAtPerkins\n",
            "Retrieved 199 tweets for: MillersAleHouse\n",
            "Retrieved 198 tweets for: JetsPizza\n",
            "Retrieved 193 tweets for: ZoesKitchen\n",
            "Retrieved 199 tweets for: peetscoffee\n",
            "Retrieved 200 tweets for: BlazePizza\n",
            "Retrieved 200 tweets for: bostonmarket\n",
            "Retrieved 194 tweets for: OCharleys\n",
            "Retrieved 198 tweets for: jerseymikes\n",
            "Retrieved 200 tweets for: bjsrestaurants\n",
            "Retrieved 200 tweets for: Bojangles\n",
            "Retrieved 200 tweets for: TimHortons\n",
            "Retrieved 200 tweets for: DennysDiner\n",
            "Retrieved 200 tweets for: Chilis\n",
            "Retrieved 199 tweets for: Outback\n",
            "Retrieved 200 tweets for: Moes_HQ\n",
            "Retrieved 200 tweets for: FirehouseSubs\n",
            "Retrieved 194 tweets for: DutchBros\n",
            "Retrieved 199 tweets for: RoundTablePizza\n",
            "Retrieved 200 tweets for: pollotropical\n",
            "Retrieved 200 tweets for: YardHouse\n",
            "Retrieved 195 tweets for: MellowMushroom\n",
            "Retrieved 199 tweets for: texasroadhouse\n",
            "Retrieved 199 tweets for: olivegarden\n",
            "Retrieved 200 tweets for: CrackerBarrel\n",
            "Retrieved 200 tweets for: PapaJohns\n",
            "Retrieved 200 tweets for: habitburger\n",
            "Retrieved 193 tweets for: Zaxbys\n",
            "Retrieved 199 tweets for: BWWings\n",
            "Retrieved 194 tweets for: MarcosPizza\n",
            "Retrieved 199 tweets for: McDonalds\n",
            "Retrieved 199 tweets for: CarlsJr\n",
            "3 iterations through while loop. 359 images retrieved.\n",
            "waiting 5 minutes...\n"
          ]
        }
      ],
      "source": [
        "reply_tweetDf, userDf = get_api_data(twitter_handles, replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "noreply_tweetDf, userDf = get_api_data(twitter_handles, replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)\n",
        "\n",
        "# reply_tweetDf, userDf = get_api_data(['McDonalds'], replies = True, numTweets = 80, tweetsPerPage = 80, print_status=True)\n",
        "# noreply_tweetDf, userDf = get_api_data(['McDonalds', 'RuthsChris'], replies = False, numTweets = 300, tweetsPerPage = 100,print_status=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "76244"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handle</th>\n",
              "      <th>followers</th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>reply_settings</th>\n",
              "      <th>...</th>\n",
              "      <th>contains_quote</th>\n",
              "      <th>is_reply</th>\n",
              "      <th>num_referenced_tweets</th>\n",
              "      <th>url_image</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>text_first_hashtag</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>num_cashtags</th>\n",
              "      <th>num_polls</th>\n",
              "      <th>interaction_score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1111396547353341952</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599599</td>\n",
              "      <td>I’ll never forget the friends I made at happy ...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>52</td>\n",
              "      <td>2</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134206851682377728</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599599</td>\n",
              "      <td>mimosas are the champagne of OJ</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134208864180736001</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599599</td>\n",
              "      <td>If there had been a boneless wings club in hig...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>29</td>\n",
              "      <td>10</td>\n",
              "      <td>109</td>\n",
              "      <td>10</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134211884570296320</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599599</td>\n",
              "      <td>Beer should start a podcast</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>54</td>\n",
              "      <td>3</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1134214148538142725</th>\n",
              "      <td>Applebees</td>\n",
              "      <td>599599</td>\n",
              "      <td>best shot/worst shot?</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>9</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250441241340162048</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263463</td>\n",
              "      <td>Take advantage of that free delivery fam at ht...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250499200804179979</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263463</td>\n",
              "      <td>Free Wingstop delivery has no competition. htt...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>67</td>\n",
              "      <td>16</td>\n",
              "      <td>339</td>\n",
              "      <td>12</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250544447798104067</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263463</td>\n",
              "      <td>Wingstop + _________. Fill in the blank for ho...</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>39</td>\n",
              "      <td>10</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>WingingitFromHome</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289274555794677760</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263463</td>\n",
              "      <td>Salute to ya (^-^)ゝ https://t.co/fhdPMcRFO8</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>252</td>\n",
              "      <td>8</td>\n",
              "      <td>1034</td>\n",
              "      <td>36</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.005409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358600587059884035</th>\n",
              "      <td>wingstop</td>\n",
              "      <td>263463</td>\n",
              "      <td>who ate the last wing ? \\n\\nwasn't me</td>\n",
              "      <td>en</td>\n",
              "      <td>False</td>\n",
              "      <td>29</td>\n",
              "      <td>25</td>\n",
              "      <td>332</td>\n",
              "      <td>6</td>\n",
              "      <td>everyone</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76244 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        handle  followers  \\\n",
              "id                                          \n",
              "1111396547353341952  Applebees     599599   \n",
              "1134206851682377728  Applebees     599599   \n",
              "1134208864180736001  Applebees     599599   \n",
              "1134211884570296320  Applebees     599599   \n",
              "1134214148538142725  Applebees     599599   \n",
              "...                        ...        ...   \n",
              "1250441241340162048   wingstop     263463   \n",
              "1250499200804179979   wingstop     263463   \n",
              "1250544447798104067   wingstop     263463   \n",
              "1289274555794677760   wingstop     263463   \n",
              "1358600587059884035   wingstop     263463   \n",
              "\n",
              "                                                                  text lang  \\\n",
              "id                                                                            \n",
              "1111396547353341952  I’ll never forget the friends I made at happy ...   en   \n",
              "1134206851682377728                    mimosas are the champagne of OJ   en   \n",
              "1134208864180736001  If there had been a boneless wings club in hig...   en   \n",
              "1134211884570296320                        Beer should start a podcast   en   \n",
              "1134214148538142725                              best shot/worst shot?   en   \n",
              "...                                                                ...  ...   \n",
              "1250441241340162048  Take advantage of that free delivery fam at ht...   en   \n",
              "1250499200804179979  Free Wingstop delivery has no competition. htt...   en   \n",
              "1250544447798104067  Wingstop + _________. Fill in the blank for ho...   en   \n",
              "1289274555794677760        Salute to ya (^-^)ゝ https://t.co/fhdPMcRFO8   en   \n",
              "1358600587059884035              who ate the last wing ? \\n\\nwasn't me   en   \n",
              "\n",
              "                     possibly_sensitive  retweet_count  reply_count  \\\n",
              "id                                                                    \n",
              "1111396547353341952               False             10            3   \n",
              "1134206851682377728               False              6            1   \n",
              "1134208864180736001               False             29           10   \n",
              "1134211884570296320               False              9            6   \n",
              "1134214148538142725               False              1           18   \n",
              "...                                 ...            ...          ...   \n",
              "1250441241340162048               False              2            8   \n",
              "1250499200804179979               False             67           16   \n",
              "1250544447798104067               False              6           15   \n",
              "1289274555794677760               False            252            8   \n",
              "1358600587059884035               False             29           25   \n",
              "\n",
              "                     like_count  quote_count reply_settings  ...  \\\n",
              "id                                                           ...   \n",
              "1111396547353341952          52            2       everyone  ...   \n",
              "1134206851682377728          53            1       everyone  ...   \n",
              "1134208864180736001         109           10       everyone  ...   \n",
              "1134211884570296320          54            3       everyone  ...   \n",
              "1134214148538142725          40            9       everyone  ...   \n",
              "...                         ...          ...            ...  ...   \n",
              "1250441241340162048          28            0       everyone  ...   \n",
              "1250499200804179979         339           12       everyone  ...   \n",
              "1250544447798104067          39           10       everyone  ...   \n",
              "1289274555794677760        1034           36       everyone  ...   \n",
              "1358600587059884035         332            6       everyone  ...   \n",
              "\n",
              "                    contains_quote is_reply  num_referenced_tweets  url_image  \\\n",
              "id                                                                              \n",
              "1111396547353341952          False    False                      0              \n",
              "1134206851682377728          False    False                      0              \n",
              "1134208864180736001          False    False                      0              \n",
              "1134211884570296320          False    False                      0              \n",
              "1134214148538142725          False    False                      0              \n",
              "...                            ...      ...                    ...        ...   \n",
              "1250441241340162048           True    False                      1              \n",
              "1250499200804179979          False    False                      0              \n",
              "1250544447798104067          False    False                      0              \n",
              "1289274555794677760          False    False                      0              \n",
              "1358600587059884035          False    False                      0              \n",
              "\n",
              "                     num_hashtags  text_first_hashtag num_mentions  \\\n",
              "id                                                                   \n",
              "1111396547353341952             0                                0   \n",
              "1134206851682377728             0                                0   \n",
              "1134208864180736001             0                                0   \n",
              "1134211884570296320             0                                0   \n",
              "1134214148538142725             0                                0   \n",
              "...                           ...                 ...          ...   \n",
              "1250441241340162048             0                                0   \n",
              "1250499200804179979             0                                0   \n",
              "1250544447798104067             1   WingingitFromHome            0   \n",
              "1289274555794677760             0                                0   \n",
              "1358600587059884035             0                                0   \n",
              "\n",
              "                     num_cashtags num_polls  interaction_score  \n",
              "id                                                              \n",
              "1111396547353341952             0         0           0.000112  \n",
              "1134206851682377728             0         0           0.000083  \n",
              "1134208864180736001             0         0           0.000319  \n",
              "1134211884570296320             0         0           0.000120  \n",
              "1134214148538142725             0         0           0.000128  \n",
              "...                           ...       ...                ...  \n",
              "1250441241340162048             0         0           0.000106  \n",
              "1250499200804179979             0         0           0.001649  \n",
              "1250544447798104067             0         0           0.000351  \n",
              "1289274555794677760             0         0           0.005409  \n",
              "1358600587059884035             0         0           0.001146  \n",
              "\n",
              "[76244 rows x 23 columns]"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "noreply_tweetDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "noreply_tweetDf.to_csv('noReplies.csv')\n",
        "reply_tweetDf.to_csv('replies.csv')\n",
        "userDf.to_csv('userData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "251"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(noreply_tweetDf[noreply_tweetDf.url_image != \"\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "455-final-project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
